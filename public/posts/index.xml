<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on My New Hugo Site</title>
    <link>https://example.org/posts/</link>
    <description>Recent content in Posts on My New Hugo Site</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Jul 2025 11:05:28 +0000</lastBuildDate>
    <atom:link href="https://example.org/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Blackwell Note</title>
      <link>https://example.org/posts/blackwell-note/</link>
      <pubDate>Mon, 14 Jul 2025 11:05:28 +0000</pubDate>
      <guid>https://example.org/posts/blackwell-note/</guid>
      <description>&lt;h1 id=&#34;wgmma-and-umma&#34;&gt;WGMMA and UMMA&lt;/h1&gt;&#xA;&lt;p&gt;So first, this blog starts with comparing the old version of mma comes from hopper architecture. It&amp;rsquo;s called wgmma, stands for warp grouped matrix multiply-accumulation.&lt;/p&gt;&#xA;&lt;p&gt;The feature of this wgmma, is the asynchronous instruction feature for matrix operation on Tensor core. It enables overlap of computation with other work, improve the efficiency.&lt;/p&gt;&#xA;&lt;p&gt;The new mma called umma, which stands for unified matrix multiply-accumulate. It&amp;rsquo;s lib is called tcgen05, which stands for tensor core generation5. (blackwell is the 5th gen Tensor cores)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Black well note claude 2</title>
      <link>https://example.org/posts/black-well-note-claude-2/</link>
      <pubDate>Mon, 14 Jul 2025 10:51:18 +0000</pubDate>
      <guid>https://example.org/posts/black-well-note-claude-2/</guid>
      <description>&lt;h1 id=&#34;nvidia-blackwell-mixed-precision-gemm-notes&#34;&gt;NVIDIA Blackwell Mixed-Precision GEMM Notes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;&#xA;&lt;p&gt;This note covers low-precision computation in NVIDIA Blackwell architecture, focusing on mixed-precision GEMM operations with sub-byte formats (FP8, FP6, FP4) and their implementation in CUTLASS.&lt;/p&gt;&#xA;&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts&lt;/h2&gt;&#xA;&lt;h3 id=&#34;tma-tensor-memory-accelerator&#34;&gt;TMA (Tensor Memory Accelerator)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Hardware unit for efficient memory transfers between Global Memory (GMEM) and Shared Memory (SMEM)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Features&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Automated multi-dimensional tensor transfers (1D to 5D)&lt;/li&gt;&#xA;&lt;li&gt;Asynchronous operation (overlaps with computation)&lt;/li&gt;&#xA;&lt;li&gt;Data format transformations during transfer&lt;/li&gt;&#xA;&lt;li&gt;Layout conversions, precision conversions, sub-byte unpacking&lt;/li&gt;&#xA;&lt;li&gt;Scatter/gather operations, padding, boundary handling&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;mixed-input-umma&#34;&gt;Mixed-Input UMMA&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: UMMA operations where matrices A and B can have different data types&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Matrix A (FP8) × Matrix B (FP6) → Matrix C (FP16)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;PTX Instruction&lt;/strong&gt;: &lt;code&gt;tcgen05.mma.mixed.m16n8k32.kind::f8f6f4&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;data-format-transformations&#34;&gt;Data Format Transformations&lt;/h2&gt;&#xA;&lt;h3 id=&#34;packed-vs-unpacked-formats&#34;&gt;Packed vs Unpacked Formats&lt;/h3&gt;&#xA;&lt;h4 id=&#34;packed-format-storage-in-gmem&#34;&gt;Packed Format (Storage in GMEM)&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;FP4: [A1A2][B1B2] - 2 values per byte&#xA;FP6: [A1A2A3][B1B2B3] - 4 values per 3 bytes  &#xA;FP8: [A1][B1] - 1 value per byte&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;unpacked-format-required-by-f8f6f4-umma&#34;&gt;Unpacked Format (Required by f8f6f4 UMMA)&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;FP4: [A1--][A2--][B1--][B2--] - 1 value per byte (padded)&#xA;FP6: [A1--][A2--][B1--][B2--] - 1 value per byte (padded)&#xA;FP8: [A1][B1] - 1 value per byte (unchanged)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;tmas-role-in-unpacking&#34;&gt;TMA&amp;rsquo;s Role in Unpacking&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt;: Packed data in GMEM&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Process&lt;/strong&gt;: Automatic unpacking during transfer&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: Unpacked data in SMEM (UMMA-friendly format)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Point&lt;/strong&gt;: Data precision unchanged, only memory layout reorganized&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;f8f6f4-umma-constraints&#34;&gt;f8f6f4 UMMA Constraints&lt;/h2&gt;&#xA;&lt;h3 id=&#34;fixed-dimensions&#34;&gt;Fixed Dimensions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;K extent&lt;/strong&gt;: Always 32 elements&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Memory requirement&lt;/strong&gt;: 32 elements × 1 byte = 32 bytes in SMEM&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Reason&lt;/strong&gt;: Hardware constraint for mixed-precision operations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;tma-alignment-requirements&#34;&gt;TMA Alignment Requirements&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Base address&lt;/strong&gt;: 32B aligned (vs usual 16B)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Leading dimension&lt;/strong&gt;: Multiple of 128 elements&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Swizzling&lt;/strong&gt;: Only 128B patterns supported&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;cutlass-stricter-alignment&#34;&gt;CUTLASS Stricter Alignment&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;FP4 data&lt;/strong&gt;: 64-byte aligned (128 elements × 0.5 bytes = 64 bytes)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;FP6 data&lt;/strong&gt;: 96-byte aligned (128 elements × 0.75 bytes = 96 bytes)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Ensures every row&amp;rsquo;s first element meets TMA alignment requirements&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;memory-source-limitations&#34;&gt;Memory Source Limitations&lt;/h2&gt;&#xA;&lt;h3 id=&#34;umma-operand-sources&#34;&gt;UMMA Operand Sources&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Allowed&lt;/strong&gt;: A from TMEM, B from SMEM ✓&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Allowed&lt;/strong&gt;: A from SMEM, B from SMEM ✓&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Not Allowed&lt;/strong&gt;: A from TMEM, B from TMEM ❌&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Not Allowed&lt;/strong&gt;: A from SMEM, B from TMEM ❌&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;tmem-requirements&#34;&gt;TMEM Requirements&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;All sub-byte data must be padded to 1 byte per value&lt;/li&gt;&#xA;&lt;li&gt;Only operand A can source from TMEM&lt;/li&gt;&#xA;&lt;li&gt;Operand B restricted to SMEM only&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;deepseeks-two-level-accumulation&#34;&gt;DeepSeek&amp;rsquo;s Two-Level Accumulation&lt;/h2&gt;&#xA;&lt;h3 id=&#34;the-problem&#34;&gt;The Problem&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;FP8 Tensor Cores use ~14-bit precision accumulation (not full FP32)&lt;/li&gt;&#xA;&lt;li&gt;Causes training inaccuracies for large models&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;deepseeks-solution&#34;&gt;DeepSeek&amp;rsquo;s Solution&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Level 1&lt;/strong&gt;: 4 consecutive WGMMA operations in Tensor Cores (FP8 accumulation)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Level 2&lt;/strong&gt;: Add partial result to FP32 accumulator using CUDA Cores&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Benefits&lt;/strong&gt;: Speed of FP8 + accuracy of FP32 accumulation&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;alternative-data-types&#34;&gt;Alternative Data Types&lt;/h2&gt;&#xA;&lt;h3 id=&#34;mxf4-type&#34;&gt;mxf4 Type&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Supports&lt;/strong&gt;: Packed SMEM format (2 FP4 values per byte)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Usage&lt;/strong&gt;: FP4-only operations (not mixed-precision)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Advantage&lt;/strong&gt;: Better memory efficiency&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TMA Type&lt;/strong&gt;: &lt;code&gt;CU_TENSOR_MAP_DATA_TYPE_16U4_ALIGN8B&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;cute-integration&#34;&gt;CuTe Integration&lt;/h3&gt;&#xA;&lt;h4 id=&#34;type-transformation-in-cutlass&#34;&gt;Type Transformation in CUTLASS&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// User specifies&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; ElementA &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cutlass&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;float_e2m3_t;  &lt;span style=&#34;color:#75715e&#34;&gt;// Packed FP8&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Builder transforms to&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; ElementAMma &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cutlass&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;float_e2m3_unpacksmem_t;  &lt;span style=&#34;color:#75715e&#34;&gt;// Unpacked FP8&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;smem-layout-selection&#34;&gt;SMEM Layout Selection&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Unified layout for all sub-byte types (after unpacking)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; ElementAMma_SmemAllocType &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cute&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;conditional_t&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;cute&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;sizeof_bits_v&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;ElementAMma&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        &lt;span style=&#34;color:#66d9ef&#34;&gt;uint8_t&lt;/span&gt;, ElementAMma&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Architecture-specific layout optimization&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; SmemLayoutAtomA &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;decltype&lt;/span&gt;(sm100_smem_selector&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;...&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;());  &lt;span style=&#34;color:#75715e&#34;&gt;// SM 100 = Blackwell&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;architecture-evolution&#34;&gt;Architecture Evolution&lt;/h2&gt;&#xA;&lt;h3 id=&#34;sm-streaming-multiprocessor-generations&#34;&gt;SM (Streaming Multiprocessor) Generations&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;SM 70&lt;/strong&gt;: Volta (V100)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SM 80&lt;/strong&gt;: Ampere (A100)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SM 90&lt;/strong&gt;: Hopper (H100)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SM 100&lt;/strong&gt;: Blackwell (B100, GB200)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;blackwell-specific-features&#34;&gt;Blackwell-Specific Features&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Mixed-precision UMMA (f8f6f4)&lt;/li&gt;&#xA;&lt;li&gt;Tensor Memory (TMEM) support&lt;/li&gt;&#xA;&lt;li&gt;Enhanced TMA capabilities&lt;/li&gt;&#xA;&lt;li&gt;New swizzling patterns for optimal performance&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Mixed-precision GEMM&lt;/strong&gt; enables different data types for A and B matrices&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TMA automatically unpacks&lt;/strong&gt; sub-byte data during GMEM→SMEM transfer&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;f8f6f4 UMMA requires unpacked format&lt;/strong&gt; (1 byte per value) in SMEM&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strict alignment requirements&lt;/strong&gt; ensure every row meets TMA constraints&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;CUTLASS abstracts complexity&lt;/strong&gt; through builder system and type transformations&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Architecture-specific optimizations&lt;/strong&gt; maximize performance on each GPU generation&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;memory-efficiency-trade-offs&#34;&gt;Memory Efficiency Trade-offs&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Format&lt;/th&gt;&#xA;          &lt;th&gt;Memory Usage&lt;/th&gt;&#xA;          &lt;th&gt;Access Speed&lt;/th&gt;&#xA;          &lt;th&gt;Use Case&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Packed SMEM&lt;/td&gt;&#xA;          &lt;td&gt;High efficiency&lt;/td&gt;&#xA;          &lt;td&gt;Complex access&lt;/td&gt;&#xA;          &lt;td&gt;FP4-only operations&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Unpacked SMEM&lt;/td&gt;&#xA;          &lt;td&gt;2x overhead (FP4)&lt;/td&gt;&#xA;          &lt;td&gt;Fast access&lt;/td&gt;&#xA;          &lt;td&gt;Mixed-precision operations&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;TMEM&lt;/td&gt;&#xA;          &lt;td&gt;1 byte/value&lt;/td&gt;&#xA;          &lt;td&gt;Fastest&lt;/td&gt;&#xA;          &lt;td&gt;Single operand optimization&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Nvidia Blackwell UMMA Architecture Guide - Part One</title>
      <link>https://example.org/posts/nvidia-blackwell-umma-architecture-guide---part-one/</link>
      <pubDate>Mon, 14 Jul 2025 07:15:24 +0000</pubDate>
      <guid>https://example.org/posts/nvidia-blackwell-umma-architecture-guide---part-one/</guid>
      <description>&lt;h1 id=&#34;nvidia-blackwell-umma-architecture-guide---part-one&#34;&gt;NVIDIA Blackwell UMMA Architecture Guide - Part One&lt;/h1&gt;&#xA;&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;&#xA;&lt;p&gt;This guide covers the fundamental concepts of NVIDIA&amp;rsquo;s Blackwell GPU architecture, focusing on the transition from Hopper&amp;rsquo;s WGMMA to Blackwell&amp;rsquo;s UMMA (Unified Matrix Multiply-Accumulate) instruction and the introduction of Tensor Memory (TMEM).&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-from-hopper-wgmma-to-blackwell-umma&#34;&gt;1. From Hopper WGMMA to Blackwell UMMA&lt;/h2&gt;&#xA;&lt;h3 id=&#34;wgmma-hopper-architecture&#34;&gt;WGMMA (Hopper Architecture)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Full Name&lt;/strong&gt;: Warp Group Matrix Multiply-Accumulate&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Nature&lt;/strong&gt;: Asynchronous instruction for matrix operations on Tensor Cores&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Launch Model&lt;/strong&gt;: Multi-threaded (multiple threads coordinate to launch)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Benefits of Async&lt;/strong&gt;: Enables overlap of computation with other work, better resource utilization&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;umma-blackwell-architecture&#34;&gt;UMMA (Blackwell Architecture)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Full Name&lt;/strong&gt;: Unified Matrix Multiply-Accumulate (CUTLASS terminology for &lt;code&gt;tcgen05.mma&lt;/code&gt;)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why tcgen05&lt;/strong&gt;: Tensor Core Generation 5 (Blackwell = 5th gen Tensor Cores)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Launch Model&lt;/strong&gt;: Single-threaded (only one thread launches the operation)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Operations Supported&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;D = A × B + D&lt;/code&gt; (multiply-accumulate)&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;D = A × B&lt;/code&gt; (multiply only)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;key-evolution-tma--umma-analogy&#34;&gt;Key Evolution: TMA → UMMA Analogy&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;TMA (Tensor Memory Accelerator)&lt;/strong&gt;: Made data copying single-threaded and register-efficient&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;UMMA&lt;/strong&gt;: Applies the same principles to matrix operations&lt;/li&gt;&#xA;&lt;li&gt;Both follow the pattern: &lt;strong&gt;offload complexity from software to dedicated hardware&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2-tensor-memory-tmem&#34;&gt;2. Tensor Memory (TMEM)&lt;/h2&gt;&#xA;&lt;h3 id=&#34;what-is-tmem&#34;&gt;What is TMEM?&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Dedicated on-chip memory for UMMA accumulation operations&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Fast storage for intermediate matrix computation results&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Capacity&lt;/strong&gt;: 128 rows (fixed) × variable columns&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;tmem-allocation&#34;&gt;TMEM Allocation&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Allocation syntax&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;tcgen05.alloc.b32 &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;tmem_descriptor, num_columns;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Requirements:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// - Minimum 32 columns&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// - Must be power of 2 (32, 64, 128, 256, etc.)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// - Allocation returns a descriptor/address&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// - Must explicitly deallocate with tcgen05.dealloc&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;tmem-vs-other-memory-types&#34;&gt;TMEM vs Other Memory Types&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;TMEM ≠ Shared Memory&#xA;├── TMEM: Dedicated tensor computation space&#xA;└── Shared Memory: Stores TMEM descriptors/addresses for coordination&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;memory-access-restrictions&#34;&gt;Memory Access Restrictions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Per-Warp Access&lt;/strong&gt;: Each warp can only access specific lanes&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Warp 0: Lanes 0-31&lt;/li&gt;&#xA;&lt;li&gt;Warp 1: Lanes 32-63&lt;/li&gt;&#xA;&lt;li&gt;Warp 2: Lanes 64-95&lt;/li&gt;&#xA;&lt;li&gt;Warp 3: Lanes 96-127&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Implication&lt;/strong&gt;: TMEM cannot be used for inter-warp data exchange&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;3-umma-operation-details&#34;&gt;3. UMMA Operation Details&lt;/h2&gt;&#xA;&lt;h3 id=&#34;matrix-operation-capabilities&#34;&gt;Matrix Operation Capabilities&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Supported Shapes&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;64 × N × 16 (N = multiple of 8, max 256)&lt;/li&gt;&#xA;&lt;li&gt;128 × N × 16 (N = multiple of 16, max 256)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Largest Atom&lt;/strong&gt;: 128 × 256 × 16 (twice the size of largest WGMMA)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;performance-optimization&#34;&gt;Performance Optimization&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pipeline Efficiency&lt;/strong&gt;: Largest UMMA uses only 50% of TMEM&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Benefit&lt;/strong&gt;: Multiple UMMA operations can pipeline without performance loss&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Result&lt;/strong&gt;: Continuous execution, maximum throughput&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;input-descriptors&#34;&gt;Input Descriptors&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Matrix Descriptors&lt;/strong&gt;: 64-bit values containing address, layout, and swizzling info&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Special Case&lt;/strong&gt;: If matrix A comes from TMEM, descriptor is replaced by simple TMEM address&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Instruction Descriptor&lt;/strong&gt;: 32-bit metadata containing:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data type and sparsity information&lt;/li&gt;&#xA;&lt;li&gt;Transpose/negate flags for A and B matrices&lt;/li&gt;&#xA;&lt;li&gt;Accumulation control (&lt;code&gt;enable-input-d&lt;/code&gt;)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;4-key-features-and-capabilities&#34;&gt;4. Key Features and Capabilities&lt;/h2&gt;&#xA;&lt;h3 id=&#34;data-layout-and-swizzling&#34;&gt;Data Layout and Swizzling&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Swizzling&lt;/strong&gt;: Data rearrangement to optimize hardware access patterns&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Avoid memory bank conflicts, enable coalesced access&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Expected Layout&lt;/strong&gt;: K-major format in shared memory&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hardware Transpose&lt;/strong&gt;: &amp;ldquo;Free&amp;rdquo; transpose during memory read (no computation cost)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;advanced-features&#34;&gt;Advanced Features&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sparsity Support&lt;/strong&gt;: Hardware optimization for matrices with many zeros&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Transpose/Negate&lt;/strong&gt;: Built-in matrix transformations during operation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Accumulation Control&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Zero out: &lt;code&gt;D = A × B&lt;/code&gt; (fresh start)&lt;/li&gt;&#xA;&lt;li&gt;Accumulate: &lt;code&gt;D = A × B + D&lt;/code&gt; (add to existing)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;cta-pairs-and-multi-sm-coordination&#34;&gt;CTA Pairs and Multi-SM Coordination&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;CTA Pair&lt;/strong&gt;: Two adjacent CTAs within an SM cluster working together&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Launch Model&lt;/strong&gt;: Even with CTA pairs, only one thread in one CTA launches UMMA&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hardware Coordination&lt;/strong&gt;: Automatic coordination between CTAs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;5-memory-movement-operations&#34;&gt;5. Memory Movement Operations&lt;/h2&gt;&#xA;&lt;h3 id=&#34;tmem-data-flow&#34;&gt;TMEM Data Flow&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Data IN:  UMMA operations → TMEM&#xA;Data OUT: tcgen05.ld → RMEM (registers)&#xA;Manual:   tcgen05.cp (SMEM→TMEM), tcgen05.st (RMEM→TMEM)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;memory-space-terminology&#34;&gt;Memory Space Terminology&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;GMEM&lt;/strong&gt;: Global Memory&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SMEM&lt;/strong&gt;: Shared Memory&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TMEM&lt;/strong&gt;: Tensor Memory&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RMEM&lt;/strong&gt;: Register Memory (registers)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;6-epilogue-processing&#34;&gt;6. Epilogue Processing&lt;/h2&gt;&#xA;&lt;h3 id=&#34;definition&#34;&gt;Definition&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Epilogue&lt;/strong&gt;: Post-processing operations after main matrix multiplication&lt;/p&gt;</description>
    </item>
    <item>
      <title>Idea</title>
      <link>https://example.org/posts/idea/</link>
      <pubDate>Mon, 14 Jul 2025 02:08:08 +0000</pubDate>
      <guid>https://example.org/posts/idea/</guid>
      <description></description>
    </item>
    <item>
      <title>yabai short key setting</title>
      <link>https://example.org/posts/yabai-short-key-setting/</link>
      <pubDate>Sat, 12 Jul 2025 07:26:05 +0000</pubDate>
      <guid>https://example.org/posts/yabai-short-key-setting/</guid>
      <description>&lt;h1 id=&#34;basic-skhdrc-configuration-for-yabai&#34;&gt;Basic .skhdrc configuration for yabai&lt;/h1&gt;&#xA;&lt;h1 id=&#34;save-this-as-skhdrc&#34;&gt;Save this as ~/.skhdrc&lt;/h1&gt;&#xA;&lt;h1 id=&#34;navigation---focus-windows&#34;&gt;Navigation - focus windows&lt;/h1&gt;&#xA;&lt;p&gt;alt - h : yabai -m window &amp;ndash;focus west&#xA;alt - j : yabai -m window &amp;ndash;focus south&#xA;alt - k : yabai -m window &amp;ndash;focus north&#xA;alt - l : yabai -m window &amp;ndash;focus east&lt;/p&gt;&#xA;&lt;h1 id=&#34;moving-windows&#34;&gt;Moving windows&lt;/h1&gt;&#xA;&lt;p&gt;shift + alt - h : yabai -m window &amp;ndash;warp west&#xA;shift + alt - j : yabai -m window &amp;ndash;warp south&#xA;shift + alt - k : yabai -m window &amp;ndash;warp north&#xA;shift + alt - l : yabai -m window &amp;ndash;warp east&lt;/p&gt;</description>
    </item>
    <item>
      <title>albert feature</title>
      <link>https://example.org/posts/albert-feature/</link>
      <pubDate>Fri, 11 Jul 2025 08:09:00 +0000</pubDate>
      <guid>https://example.org/posts/albert-feature/</guid>
      <description>&lt;p&gt;ALBERT (&lt;strong&gt;A&lt;/strong&gt; &lt;strong&gt;L&lt;/strong&gt;ight&lt;strong&gt;B&lt;/strong&gt;i-directional &lt;strong&gt;E&lt;/strong&gt;ncoder &lt;strong&gt;R&lt;/strong&gt;epresentations from &lt;strong&gt;T&lt;/strong&gt;ransformers) is a lite version of the BERT (Bidirectional Encoder Representations from Transformers) model, designed to reduce memory consumption and increase training speed.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;albert-factorization&#34;&gt;ALBERT Factorization&lt;/h2&gt;&#xA;&lt;p&gt;ALBERT factorization refers to the method ALBERT uses to reduce the number of parameters in the embedding layer. In traditional BERT models, the vocabulary embedding size (E) is tied to the hidden layer size (H), meaning E = H. This can lead to a very large number of parameters, especially with large vocabularies. ALBERT addresses this by &lt;strong&gt;factorizing the embedding parameters into two smaller matrices&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bert CLS token Study Notes</title>
      <link>https://example.org/posts/bert-cls-token-study-notes/</link>
      <pubDate>Fri, 11 Jul 2025 07:57:38 +0000</pubDate>
      <guid>https://example.org/posts/bert-cls-token-study-notes/</guid>
      <description>&lt;h1 id=&#34;bert-cls-token---study-notes&#34;&gt;BERT [CLS] Token - Study Notes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;bert-output-structure&#34;&gt;BERT Output Structure&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BERT outputs hidden representations for each input token position&lt;/li&gt;&#xA;&lt;li&gt;Example: &lt;code&gt;[CLS] hello world [SEP]&lt;/code&gt; → 4 hidden vectors (one per token)&lt;/li&gt;&#xA;&lt;li&gt;Each position gets a contextual representation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-is-the-cls-token&#34;&gt;What is the [CLS] Token?&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Designated position for sequence-level information aggregation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Mechanism&lt;/strong&gt;: Uses self-attention to &amp;ldquo;see&amp;rdquo; and combine info from all other tokens&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Design&lt;/strong&gt;: Has no inherent meaning, so it&amp;rsquo;s free to learn task-specific representations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;key-point-cannot-use-cls-directly&#34;&gt;Key Point: Cannot Use [CLS] Directly&lt;/h2&gt;&#xA;&lt;p&gt;❌ &lt;strong&gt;Pre-trained [CLS] won&amp;rsquo;t work for your task&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>What&#39;s Contextual Attention</title>
      <link>https://example.org/posts/whats-contextual-attention/</link>
      <pubDate>Fri, 11 Jul 2025 07:21:58 +0000</pubDate>
      <guid>https://example.org/posts/whats-contextual-attention/</guid>
      <description>&lt;h1 id=&#34;self-attention-vs-contextual-attention&#34;&gt;Self-Attention vs Contextual Attention&lt;/h1&gt;&#xA;&lt;h2 id=&#34;important-clarification&#34;&gt;Important Clarification&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;&amp;ldquo;Contextual attention&amp;rdquo; is not a standard term in the field.&lt;/strong&gt; You might be thinking of different types of attention mechanisms. Let me explain the key distinctions:&lt;/p&gt;&#xA;&lt;h2 id=&#34;self-attention-standard-term&#34;&gt;Self-Attention (Standard Term)&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Each token attends to all tokens in the same sequence (including itself)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Key Characteristics&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Input sequence: [&amp;ldquo;The&amp;rdquo;, &amp;ldquo;bank&amp;rdquo;, &amp;ldquo;river&amp;rdquo;, &amp;ldquo;flows&amp;rdquo;]&lt;/li&gt;&#xA;&lt;li&gt;Each word looks at ALL words in the same sentence&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;bank&amp;rdquo; attends to: &amp;ldquo;The&amp;rdquo;, &amp;ldquo;bank&amp;rdquo;, &amp;ldquo;river&amp;rdquo;, &amp;ldquo;flows&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;Used in: BERT, GPT, most modern transformers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Formula&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Contextual Embedding</title>
      <link>https://example.org/posts/contextual-embedding/</link>
      <pubDate>Fri, 11 Jul 2025 07:21:28 +0000</pubDate>
      <guid>https://example.org/posts/contextual-embedding/</guid>
      <description>&lt;h1 id=&#34;contextual-embeddings---simple-summary&#34;&gt;Contextual Embeddings - Simple Summary&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-are-they&#34;&gt;What Are They?&lt;/h2&gt;&#xA;&lt;p&gt;Word representations that &lt;strong&gt;change based on context&lt;/strong&gt;, unlike static embeddings where each word has a fixed vector.&lt;/p&gt;&#xA;&lt;p&gt;Example: &amp;ldquo;bank&amp;rdquo; gets different embeddings in:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&amp;ldquo;river bank&amp;rdquo; (geographic)&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;savings bank&amp;rdquo; (financial)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;where-are-they-created&#34;&gt;Where Are They Created?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Inside the self-attention mechanism&lt;/strong&gt; of transformer layers.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-do-they-work&#34;&gt;How Do They Work?&lt;/h2&gt;&#xA;&lt;h3 id=&#34;the-process&#34;&gt;The Process:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Static embeddings&lt;/strong&gt; (from lookup table) + &lt;strong&gt;positional encoding&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Self-attention&lt;/strong&gt; calculates how much each word should &amp;ldquo;pay attention&amp;rdquo; to others&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Mix embeddings&lt;/strong&gt; based on attention weights → &lt;strong&gt;Contextual embeddings&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;the-formula&#34;&gt;The Formula:&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;For each token i:&#xA;contextual_embedding[i] = Σ(attention_weight[i,j] × value_embedding[j])&#xA;                         j=0 to sequence_length&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Key insight&lt;/strong&gt;: Each token&amp;rsquo;s final embedding is a weighted sum of ALL tokens in the sequence (including itself).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformer Hidden Size - Quick Notes</title>
      <link>https://example.org/posts/transformer-hidden-size---quick-notes/</link>
      <pubDate>Fri, 11 Jul 2025 04:16:29 +0000</pubDate>
      <guid>https://example.org/posts/transformer-hidden-size---quick-notes/</guid>
      <description>&lt;h1 id=&#34;transformer-hidden-size---quick-notes&#34;&gt;Transformer Hidden Size - Quick Notes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;core-concepts&#34;&gt;Core Concepts&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Hidden State&lt;/strong&gt;: The vector representation of each token at each layer&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Each token position has its own hidden state vector&lt;/li&gt;&#xA;&lt;li&gt;Content evolves through layers, but size stays constant&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Hidden Size&lt;/strong&gt;: The dimensionality of these vectors (e.g., 512, 768, 1024)&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Key architectural parameter&lt;/li&gt;&#xA;&lt;li&gt;Determines model width&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;size-relationships&#34;&gt;Size Relationships&lt;/h2&gt;&#xA;&lt;h3 id=&#34;single-head-attention&#34;&gt;Single-Head Attention&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Q, K, V dimensions = hidden_size&lt;/li&gt;&#xA;&lt;li&gt;Linear projections: hidden_size → hidden_size&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;multi-head-attention&#34;&gt;Multi-Head Attention&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;d_k = d_v = hidden_size / num_heads&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Each head: hidden_size → d_k&lt;/li&gt;&#xA;&lt;li&gt;After concat: back to hidden_size&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: hidden_size=256, heads=4&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scaling Laws</title>
      <link>https://example.org/posts/scaling-laws/</link>
      <pubDate>Fri, 11 Jul 2025 04:16:22 +0000</pubDate>
      <guid>https://example.org/posts/scaling-laws/</guid>
      <description>&lt;h1 id=&#34;neural-network-scaling-laws---study-notes&#34;&gt;Neural Network Scaling Laws - Study Notes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;core-scaling-law-formula&#34;&gt;Core Scaling Law Formula&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;L(X) = (X/X_c)^(-α_X)&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Where:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;L&lt;/strong&gt; = Loss (performance metric, lower = better)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;X&lt;/strong&gt; = Scale factor (D for data, N for parameters, C for compute)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;X_c&lt;/strong&gt; = Critical threshold (minimum scale where power laws apply)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;α_X&lt;/strong&gt; = Scaling exponent (determines improvement rate)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;three-key-scaling-dimensions&#34;&gt;Three Key Scaling Dimensions&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-data-scaling-ld--dd_c-α_d&#34;&gt;1. Data Scaling: L(D) = (D/D_c)^(-α_D)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;D&lt;/strong&gt; = Dataset size (training tokens/examples)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;D_c&lt;/strong&gt; = Critical dataset size threshold&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;α_D ≈ 0.095&lt;/strong&gt; for transformers&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Doubling data&lt;/strong&gt; → Loss × 2^(-0.095) ≈ &lt;strong&gt;6.8% improvement&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-parameter-scaling-ln--nn_c-α_n&#34;&gt;2. Parameter Scaling: L(N) = (N/N_c)^(-α_N)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;N&lt;/strong&gt; = Number of model parameters&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;N_c&lt;/strong&gt; = Critical parameter count threshold&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;α_N ≈ 0.076&lt;/strong&gt; for transformers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-compute-scaling-lc--cc_c-α_c&#34;&gt;3. Compute Scaling: L(C) = (C/C_c)^(-α_C)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;C&lt;/strong&gt; = Total compute (FLOPs)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;C_c&lt;/strong&gt; = Critical compute threshold&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;α_C&lt;/strong&gt; varies by compute allocation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;chinchilla-optimal-scaling&#34;&gt;Chinchilla Optimal Scaling&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;N_opt ∝ D_opt&lt;/strong&gt; (approximately 1:1 ratio)&lt;/p&gt;</description>
    </item>
    <item>
      <title>MUSTAFAR Blog</title>
      <link>https://example.org/posts/mustafar-blog/</link>
      <pubDate>Fri, 11 Jul 2025 02:42:22 +0000</pubDate>
      <guid>https://example.org/posts/mustafar-blog/</guid>
      <description>&lt;h1 id=&#34;key-statement-from-abstract&#34;&gt;Key statement from Abstract&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;they claims &lt;strong&gt;unstructured sparsity&lt;/strong&gt; enables sparsity levels up to &lt;strong&gt;70%&lt;/strong&gt; &lt;strong&gt;without compromising accuracy&lt;/strong&gt; or requiring fine-tuning.&lt;/li&gt;&#xA;&lt;li&gt;they did exploration of pruning strategies, and find &lt;strong&gt;per-token magnitude-based pruning&lt;/strong&gt; as highly effective for both Key and Value caches under &lt;strong&gt;unstructured sparsity&lt;/strong&gt;, surpassing prior structured pruning schemes.&lt;/li&gt;&#xA;&lt;li&gt;Value cache surprisingly benefits from a simple &lt;strong&gt;magnitude-based pruning&lt;/strong&gt; despite its uniform distribution.&lt;/li&gt;&#xA;&lt;li&gt;They use &lt;strong&gt;a bitmap-based sparse format&lt;/strong&gt; and &lt;strong&gt;a custom attention kernel&lt;/strong&gt; capable of compressing and directly &lt;strong&gt;computing over&lt;/strong&gt; caches pruned to arbitrary sparsity patterns.&lt;/li&gt;&#xA;&lt;li&gt;Their kernel coupled with the bitmap-based format delivers substantial compression of KV cache up to &lt;strong&gt;45%&lt;/strong&gt; of dense inference and increased tokens/sec throughput of up to &lt;strong&gt;2.23x&lt;/strong&gt; compared to dense inference.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;note-of-introduction&#34;&gt;Note of Introduction&lt;/h1&gt;&#xA;&lt;p&gt;Effective pruning of the KV cache entails two core challenges:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Inference Process</title>
      <link>https://example.org/posts/inference-process/</link>
      <pubDate>Sun, 06 Jul 2025 11:05:06 +0000</pubDate>
      <guid>https://example.org/posts/inference-process/</guid>
      <description>&lt;p&gt;-&lt;a href=&#34;https://claude.ai/public/artifacts/42c458f2-6add-4b92-b47d-5afa5cf3c6d3&#34;&gt;claude open&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;understanding-q-k-v-in-attention&#34;&gt;Understanding Q, K, V in Attention&lt;/h2&gt;&#xA;&lt;h3 id=&#34;what-each-represents&#34;&gt;What Each Represents&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Query (Q)&lt;/strong&gt;: &amp;ldquo;What information do I need?&amp;rdquo; - Search request&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key (K)&lt;/strong&gt;: &amp;ldquo;What information do I have?&amp;rdquo; - Advertisement/label&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Value (V)&lt;/strong&gt;: &amp;ldquo;Here&amp;rsquo;s the actual information&amp;rdquo; - Content payload&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;how-they-work-together&#34;&gt;How They Work Together&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Q × K&lt;/strong&gt;: Compute attention weights (who should attend to whom)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Softmax&lt;/strong&gt;: Normalize attention weights&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Attention × V&lt;/strong&gt;: Weighted sum of values (what information gets mixed)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;training-perspective&#34;&gt;Training Perspective&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;W_q, W_k, W_v&lt;/strong&gt;: Three learned transformation matrices&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Same input&lt;/strong&gt;: Gets transformed three different ways for different purposes&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Learning&lt;/strong&gt;: Model learns these matrices to solve language modeling task&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Token &amp;#34;queen&amp;#34; input: [0.5, 0.8, 0.2, 0.9, ...]&#xA;&#xA;After transformations:&#xA;Q = [0.000001, 1, 3, ...] # &amp;#34;I need person/musician info, not royal info&amp;#34;&#xA;K = [100, 2, 4, ...]      # &amp;#34;I&amp;#39;m very relevant for royal queries&amp;#34;&#xA;V = [1, 2, 3, ...]        # &amp;#34;I contain: royal=1, person=2, musician=3&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;llm-inference-process&#34;&gt;LLM Inference Process&lt;/h2&gt;&#xA;&lt;h3 id=&#34;two-phase-approach&#34;&gt;Two-Phase Approach&lt;/h3&gt;&#xA;&lt;h4 id=&#34;phase-1-prefilling&#34;&gt;Phase 1: Prefilling&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Process entire input prompt&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;: All tokens processed simultaneously (parallel)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: Build initial KV cache, generate first response token&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Fast due to parallelization&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;phase-2-decoding&#34;&gt;Phase 2: Decoding&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Generate response tokens one by one&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Method&lt;/strong&gt;: Sequential processing, append to KV cache&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: Complete response&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Slower due to sequential nature&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;complete-example&#34;&gt;Complete Example&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input: &amp;#34;System: You are helpful. User: What is the capital of France?&amp;#34;&#xA;&#xA;Prefilling:&#xA;- Process all 17 input tokens at once&#xA;- Build KV cache: [17 × hidden_size]&#xA;- Generate first token: &amp;#34;The&amp;#34;&#xA;&#xA;Decoding:&#xA;Time 1: Add &amp;#34;The&amp;#34; → Cache: [18 × hidden_size] → Generate &amp;#34;capital&amp;#34;&#xA;Time 2: Add &amp;#34;capital&amp;#34; → Cache: [19 × hidden_size] → Generate &amp;#34;of&amp;#34;&#xA;Time 3: Add &amp;#34;of&amp;#34; → Cache: [20 × hidden_size] → Generate &amp;#34;France&amp;#34;&#xA;...continue until complete response&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;key-insights-gained&#34;&gt;Key Insights Gained&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;KV Cache is Essential&lt;/strong&gt;: Enables efficient autoregressive generation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pruning is Nuanced&lt;/strong&gt;: Different strategies (per-channel vs per-token) serve different purposes&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output-Awareness is Smart&lt;/strong&gt;: Considers both stored information and current needs&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Q,K,V Have Distinct Roles&lt;/strong&gt;: Not just different values, but different purposes&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Inference Has Structure&lt;/strong&gt;: Prefilling vs decoding phases optimize for different constraints&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Everything Connects&lt;/strong&gt;: From training objectives to inference efficiency to pruning strategies&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;practical-applications&#34;&gt;Practical Applications&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Memory Optimization&lt;/strong&gt;: Pruning reduces KV cache size for long sequences&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Inference Acceleration&lt;/strong&gt;: Smaller cache = faster attention computation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Quality Preservation&lt;/strong&gt;: Smart pruning maintains model performance&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Enables processing of longer contexts within memory constraints&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This comprehensive understanding provides the foundation for working with modern LLM optimization techniques and understanding their trade-offs between efficiency and quality.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Two Aspects of Pruning</title>
      <link>https://example.org/posts/two-aspects-of-pruning/</link>
      <pubDate>Sun, 06 Jul 2025 10:37:09 +0000</pubDate>
      <guid>https://example.org/posts/two-aspects-of-pruning/</guid>
      <description>&lt;p&gt;-&lt;a href=&#34;https://claude.ai/public/artifacts/18d1f408-412d-42aa-af07-9853577253ba&#34;&gt;claude link&lt;/a&gt;&#xA;-&lt;a href=&#34;https://claude.ai/share/063d2d3e-1e51-4bc7-b003-b88d472b102b&#34;&gt;claude link chat&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;kv-cache-and-pruning-strategies---study-notes&#34;&gt;KV Cache and Pruning Strategies - Study Notes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-kv-cache&#34;&gt;What is KV Cache?&lt;/h2&gt;&#xA;&lt;h3 id=&#34;purpose&#34;&gt;Purpose&lt;/h3&gt;&#xA;&lt;p&gt;KV cache is a memory optimization technique used in transformer models during text generation to avoid redundant computations.&lt;/p&gt;&#xA;&lt;h3 id=&#34;how-it-works&#34;&gt;How it Works&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Without caching, generating each new token requires recomputing Key (K) and Value (V) matrices for all previous tokens&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Store K and V representations of previous tokens, only compute K and V for the new token&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;example-process&#34;&gt;Example Process&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Generating &amp;#34;The cat sat on&amp;#34;&#xA;&#xA;Step 1: Generate &amp;#34;cat&amp;#34;&#xA;- Input: &amp;#34;The&amp;#34;&#xA;- Compute K₁, V₁ for &amp;#34;The&amp;#34;&#xA;- Cache: K=[K₁], V=[V₁]&#xA;&#xA;Step 2: Generate &amp;#34;sat&amp;#34; &#xA;- Input: &amp;#34;The cat&amp;#34;&#xA;- Compute K₂, V₂ for &amp;#34;cat&amp;#34; &#xA;- Cache: K=[K₁, K₂], V=[V₁, V₂]&#xA;- Reuse K₁, V₁ (no recomputation!)&#xA;&#xA;Step 3: Generate &amp;#34;on&amp;#34;&#xA;- Input: &amp;#34;The cat sat&amp;#34;&#xA;- Compute K₃, V₃ for &amp;#34;sat&amp;#34;&#xA;- Cache: K=[K₁, K₂, K₃], V=[V₁, V₂, V₃]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;kv-cache-structure&#34;&gt;KV Cache Structure&lt;/h2&gt;&#xA;&lt;h3 id=&#34;matrix-dimensions&#34;&gt;Matrix Dimensions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Format&lt;/strong&gt;: [tokens × channels]&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tokens&lt;/strong&gt;: Sequence positions (words/subwords in the input)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Channels&lt;/strong&gt;: Feature dimensions (hidden size of the model, e.g., 768, 1024, 4096)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Growth&lt;/strong&gt;: Cache grows as sequence lengthens: [1×channels] → [2×channels] → [3×channels]&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;key-properties&#34;&gt;Key Properties&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Both K and V caches have identical dimensions&lt;/li&gt;&#xA;&lt;li&gt;Channels size is determined by model architecture&lt;/li&gt;&#xA;&lt;li&gt;Each element represents the intersection of a token and a channel&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;pruning-strategies&#34;&gt;Pruning Strategies&lt;/h2&gt;&#xA;&lt;h3 id=&#34;core-concepts&#34;&gt;Core Concepts&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pruning Direction&lt;/strong&gt;: Which axis to remove elements from&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output-Awareness&lt;/strong&gt;: Using scoring metrics to estimate element importance&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Local Dense Window&lt;/strong&gt;: Keep recent 32 tokens untouched during decoding&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;1-per-channel-pruning&#34;&gt;1. Per-Channel Pruning&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: For each channel (column), selectively remove some token entries&lt;/p&gt;</description>
    </item>
    <item>
      <title>MUSTAFAR reading note</title>
      <link>https://example.org/posts/mustafar-reading-note/</link>
      <pubDate>Sun, 06 Jul 2025 09:59:28 +0000</pubDate>
      <guid>https://example.org/posts/mustafar-reading-note/</guid>
      <description>&lt;p&gt;-&lt;a href=&#34;https://claude.ai/public/artifacts/18d1f408-412d-42aa-af07-9853577253ba&#34;&gt;claude link&lt;/a&gt;&#xA;-&lt;a href=&#34;https://claude.ai/share/063d2d3e-1e51-4bc7-b003-b88d472b102b&#34;&gt;claude link chat&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;kv-cache-and-pruning-strategies---study-notes&#34;&gt;KV Cache and Pruning Strategies - Study Notes&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-kv-cache&#34;&gt;What is KV Cache?&lt;/h2&gt;&#xA;&lt;h3 id=&#34;purpose&#34;&gt;Purpose&lt;/h3&gt;&#xA;&lt;p&gt;KV cache is a memory optimization technique used in transformer models during text generation to avoid redundant computations.&lt;/p&gt;&#xA;&lt;h3 id=&#34;how-it-works&#34;&gt;How it Works&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Without caching, generating each new token requires recomputing Key (K) and Value (V) matrices for all previous tokens&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Store K and V representations of previous tokens, only compute K and V for the new token&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;example-process&#34;&gt;Example Process&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Generating &amp;#34;The cat sat on&amp;#34;&#xA;&#xA;Step 1: Generate &amp;#34;cat&amp;#34;&#xA;- Input: &amp;#34;The&amp;#34;&#xA;- Compute K₁, V₁ for &amp;#34;The&amp;#34;&#xA;- Cache: K=[K₁], V=[V₁]&#xA;&#xA;Step 2: Generate &amp;#34;sat&amp;#34; &#xA;- Input: &amp;#34;The cat&amp;#34;&#xA;- Compute K₂, V₂ for &amp;#34;cat&amp;#34; &#xA;- Cache: K=[K₁, K₂], V=[V₁, V₂]&#xA;- Reuse K₁, V₁ (no recomputation!)&#xA;&#xA;Step 3: Generate &amp;#34;on&amp;#34;&#xA;- Input: &amp;#34;The cat sat&amp;#34;&#xA;- Compute K₃, V₃ for &amp;#34;sat&amp;#34;&#xA;- Cache: K=[K₁, K₂, K₃], V=[V₁, V₂, V₃]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;kv-cache-structure&#34;&gt;KV Cache Structure&lt;/h2&gt;&#xA;&lt;h3 id=&#34;matrix-dimensions&#34;&gt;Matrix Dimensions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Format&lt;/strong&gt;: [tokens × channels]&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tokens&lt;/strong&gt;: Sequence positions (words/subwords in the input)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Channels&lt;/strong&gt;: Feature dimensions (hidden size of the model, e.g., 768, 1024, 4096)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Growth&lt;/strong&gt;: Cache grows as sequence lengthens: [1×channels] → [2×channels] → [3×channels]&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;key-properties&#34;&gt;Key Properties&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Both K and V caches have identical dimensions&lt;/li&gt;&#xA;&lt;li&gt;Channels size is determined by model architecture&lt;/li&gt;&#xA;&lt;li&gt;Each element represents the intersection of a token and a channel&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;pruning-strategies&#34;&gt;Pruning Strategies&lt;/h2&gt;&#xA;&lt;h3 id=&#34;core-concepts&#34;&gt;Core Concepts&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pruning Direction&lt;/strong&gt;: Which axis to remove elements from&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Output-Awareness&lt;/strong&gt;: Using scoring metrics to estimate element importance&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Local Dense Window&lt;/strong&gt;: Keep recent 32 tokens untouched during decoding&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;1-per-channel-pruning&#34;&gt;1. Per-Channel Pruning&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: For each channel (column), selectively remove some token entries&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sparsity</title>
      <link>https://example.org/posts/sparsity/</link>
      <pubDate>Fri, 04 Jul 2025 14:16:29 +0000</pubDate>
      <guid>https://example.org/posts/sparsity/</guid>
      <description>&lt;h1 id=&#34;how-sparsity-is-employed-in-acceleration&#34;&gt;How sparsity is employed in Acceleration&lt;/h1&gt;&#xA;&lt;p&gt;When multiplying by zero or very small values, we can avoid the computation entirely.&lt;/p&gt;&#xA;&lt;p&gt;If 90% percent of values are zero, we can theoretically only need to compute 10% of the operations.&lt;/p&gt;&#xA;&lt;p&gt;The hardware like GPU support this acceleration in hardware way.&lt;/p&gt;&#xA;&lt;p&gt;It can:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reduce memory bandwidth. (no load zero values)&lt;/li&gt;&#xA;&lt;li&gt;Fewer arithmetic operations. (skip some multiplications and addition)&lt;/li&gt;&#xA;&lt;li&gt;Lower energy consumption. (based on previous 2 optimization)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;three-types-of-sparsity-in-llm&#34;&gt;Three types of Sparsity in LLM&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Weight Sparsity&lt;/strong&gt;: Zeros in model parameters. These weights pruned during &lt;strong&gt;training or post-training&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>面试题目收集</title>
      <link>https://example.org/posts/%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE%E6%94%B6%E9%9B%86/</link>
      <pubDate>Tue, 24 Jun 2025 15:37:09 +0000</pubDate>
      <guid>https://example.org/posts/%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE%E6%94%B6%E9%9B%86/</guid>
      <description>&lt;p&gt;ThreadsPerBlock和Blocks的数量受哪些条件约束。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ThreadsPerBlock 受 SM寄存器数量, 共享内存大小 和 硬件上限(1024 threads/block)&lt;/li&gt;&#xA;&lt;li&gt;Block数量 受 SM数量和资源容量限制(需要保证所有active blocks的资源总和不超过SM容量)&#xA;理论占用率怎么计算？&lt;/li&gt;&#xA;&lt;li&gt;Occupancy = (active warp/SM) / (max warps/SM). 它表示SM上活跃的Warp数量与最大支持的Warp数量之比. 高占用率可以更好地隐藏内存访问延迟, 提高计算吞吐量.&lt;/li&gt;&#xA;&lt;li&gt;GPU以Block为粒度分配资源(寄存器, 共享内存, 线程槽位). 而不是以Warp分配.&lt;/li&gt;&#xA;&lt;li&gt;寄存器, 共享内存, 线程调度 都是以Block为基础调度的&lt;/li&gt;&#xA;&lt;li&gt;假如SM支持最多2048个线程(64个warp), 如果每个block有256个线程, 那么SM最多能驻留8个block. 但是因为寄存器和共享内存可能达到上限, SM可能只能驻留4个block.&lt;/li&gt;&#xA;&lt;li&gt;计算每个block的warp数. Warp per Block = upper bound(Thread per Block / 32)&lt;/li&gt;&#xA;&lt;li&gt;计算SM能驻留的Block数量, 受限于 寄存器, 共享内存和线程数&lt;/li&gt;&#xA;&lt;li&gt;Active Warp = Warps Per Block x Active Block Per SM&lt;/li&gt;&#xA;&lt;li&gt;之后计算占用率&#xA;什么是warp，什么是warp divergence？&lt;/li&gt;&#xA;&lt;li&gt;Warp 是 SM的基本执行单元, 包含32个线程&lt;/li&gt;&#xA;&lt;li&gt;Warp Divergence 是同以warp内的线程执行不同branch时, 会造成不同branch串行执行, 造成性能损失.&#xA;cuda的内存模型里有多少种memory，它们的位置(片上还是板上)，带宽和延迟的相对大小？&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;register&lt;/strong&gt;, on chip, &lt;strong&gt;1&lt;/strong&gt; cycle latency, &lt;strong&gt;highest&lt;/strong&gt; bandwidth, private for &lt;strong&gt;single thread&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;shared memory&lt;/strong&gt;, on chip, &lt;strong&gt;30&lt;/strong&gt; cycle latency, &lt;strong&gt;high&lt;/strong&gt; bandwidth, shared by &lt;strong&gt;block&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;local memory&lt;/strong&gt;, off-chip, &lt;strong&gt;dram&lt;/strong&gt;, in &lt;strong&gt;global&lt;/strong&gt; memory(reality), logically private for single thread&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;global memory&lt;/strong&gt;, off-chip, &lt;strong&gt;dram&lt;/strong&gt;, 400-800 cycle, &lt;strong&gt;low&lt;/strong&gt; bandwidth, shared by all threads&lt;/li&gt;&#xA;&lt;li&gt;texture and constant, medium latency, medium bandwidth, shared by all threads&#xA;global memory的访存合并是什么？&lt;/li&gt;&#xA;&lt;li&gt;coalescing access, 同一个warp上的连续线程访问连续&lt;strong&gt;global memory&lt;/strong&gt;地址时会被合并为单个事务. gpu的global memory的事务粒度是128字节.&lt;/li&gt;&#xA;&lt;li&gt;对于shared memory的优化是避免bank conflict, 共享内存有32个bank. 避免冲突可以使用: 使用padding, 改变访问模式(转置), 使用广播机制(32个线程访问同一个bank上的内容)&lt;/li&gt;&#xA;&lt;li&gt;register分配, 对于自动分配的局部变量, 可能会溢出到local memory上.&#xA;什么样的变量会被分配在register上？&lt;/li&gt;&#xA;&lt;li&gt;分配到寄存器的变量: 小型标量(int, float&amp;hellip;), 未取地址的临时变量&lt;/li&gt;&#xA;&lt;li&gt;不会分配到寄存器的变量: 大数组, 取地址变量, 寄存器溢出&#xA;什么样的变量会被分配在local memory上？&lt;/li&gt;&#xA;&lt;li&gt;大数组&lt;/li&gt;&#xA;&lt;li&gt;动态索引的数组&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;kernel&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; index) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; arr[&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;arr[index] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; &lt;span style=&#34;color:#75715e&#34;&gt;// dynamic indexing&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;指针操作&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;kernel&lt;/span&gt;() {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;ptr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;x;  &lt;span style=&#34;color:#75715e&#34;&gt;// 取地址, register没有地址, 因此存放到local memory&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;溢出的变量&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;complex_calc&lt;/span&gt;() {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; a1, a2, a3, a4, ..., a100;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Block是怎么被SM调度执行的？&lt;/p&gt;</description>
    </item>
    <item>
      <title>DPU Memo</title>
      <link>https://example.org/posts/dpu-memo/</link>
      <pubDate>Sat, 07 Jun 2025 13:13:53 +0000</pubDate>
      <guid>https://example.org/posts/dpu-memo/</guid>
      <description>&lt;h1 id=&#34;general&#34;&gt;General&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It gets its own OS.&lt;/li&gt;&#xA;&lt;li&gt;It can process networking data by itself(installing a firewall)&lt;/li&gt;&#xA;&lt;li&gt;suitable for networking things.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Algorithm Thought</title>
      <link>https://example.org/posts/algorithm-thought/</link>
      <pubDate>Sat, 07 Jun 2025 13:13:51 +0000</pubDate>
      <guid>https://example.org/posts/algorithm-thought/</guid>
      <description>&lt;h1 id=&#34;two-aspect-of-doing-algorithm&#34;&gt;Two aspect of Doing Algorithm&lt;/h1&gt;&#xA;&lt;p&gt;There are two component of solving problem related to algorithms.&#xA;The first component is how to implement you thought. Even though you get a clear and simple way for solving algorithm problem in your mind, you still need to implement it into code. But it need practice to write a clear and right code for the algorithm in your mind.&#xA;The second part is how to get the way for solving algorithm problem. It&amp;rsquo;s more about reading and watching related books or lectures.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Algorithm Template</title>
      <link>https://example.org/posts/algorithm-template/</link>
      <pubDate>Sat, 07 Jun 2025 13:13:49 +0000</pubDate>
      <guid>https://example.org/posts/algorithm-template/</guid>
      <description>&lt;h1 id=&#34;qicksort&#34;&gt;Qicksort&lt;/h1&gt;&#xA;&lt;p&gt;leetcode: &lt;a href=&#34;https://leetcode.cn/problems/sort-an-array/description/&#34;&gt;https://leetcode.cn/problems/sort-an-array/description/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;template:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Solution&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;publick:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; quick_sort(vector&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;amp;&lt;/span&gt; q, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; l, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; r) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (l &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; r) returnkk&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;#39;&lt;/span&gt;k;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; q[l], i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; l &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; r &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt;(i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; j) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt;(q[i] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; x);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; j&lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt;(q[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; x);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; j) swap(q[i], q[j]);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        quick_sort(q, l, j);  &lt;span style=&#34;color:#75715e&#34;&gt;// if we use x = q[r], we need i - 1 here.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        quick_sort(q, j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, r); &lt;span style=&#34;color:#75715e&#34;&gt;// and i here.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vector&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; sortArray(vector&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;amp;&lt;/span&gt; nums) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nums.size();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        quick_sort(nums, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; nums;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;};&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;thought:&lt;/p&gt;</description>
    </item>
    <item>
      <title>CSAPP Memo</title>
      <link>https://example.org/posts/csapp-memo/</link>
      <pubDate>Sat, 07 Jun 2025 13:13:47 +0000</pubDate>
      <guid>https://example.org/posts/csapp-memo/</guid>
      <description>&lt;h1 id=&#34;ch1&#34;&gt;Ch1&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hardware-of-system&#34;&gt;Hardware of system&lt;/h2&gt;&#xA;&lt;h3 id=&#34;bus&#34;&gt;Bus&lt;/h3&gt;&#xA;&lt;p&gt;It&amp;rsquo;s a lot of different things, but we can describe them as a whole abstract thing, and call it bus.&#xA;There are several features of it.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It passes message base on a uniform width called WORD (4 bytes or 8 bytes).&lt;/li&gt;&#xA;&lt;li&gt;It can be implemented by different kinds of hardware(mostly PCIe).&lt;/li&gt;&#xA;&lt;li&gt;It basically connect between cpu and other components like I/O devices and Memory (in older architecture, they called southern bridge and northern bridge).&lt;/li&gt;&#xA;&lt;li&gt;People classify buses base on what they do. There are data bus, address bus and control bus.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Some key idea:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Leetcode Memo</title>
      <link>https://example.org/posts/leetcode-memo/</link>
      <pubDate>Thu, 29 May 2025 09:46:50 +0000</pubDate>
      <guid>https://example.org/posts/leetcode-memo/</guid>
      <description>&lt;h1 id=&#34;tier&#34;&gt;Tier&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://leetcode.cn/problems/maximize-the-number-of-target-nodes-after-connecting-trees-ii/&#34;&gt;3373. 连接两棵树后最大目标节点数目 II&lt;/a&gt;&#xA;The traverse of tier can be viewed as the traverse of graph.&#xA;We can do the following to traverse the tier to get depth, from root. This is based on depth first search.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# This is for build children list, for dfs&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# edges represents: [[1, 2], [2, 3], [3, 4]], i.e. node 1 links to 2 etc...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;builder&lt;/span&gt;(edges):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(edges) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#how many node&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;children &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [[] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n)]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; u, v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; edges:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;children[u]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(v)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;children[v]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(u) &lt;span style=&#34;color:#75715e&#34;&gt;#there are duplicate, so you need to check using parent == child?&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; children&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# node for current search for node, just a index for node, like 1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# parent, the parent of current searching node. &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# depth, mark depth here&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# children, comes from builder&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dfs&lt;/span&gt;(node, parent, depth, children):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#75715e&#34;&gt;# res update here&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; child &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; children[node]:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; child &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; parent: &lt;span style=&#34;color:#75715e&#34;&gt;# for duplicate checking&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#75715e&#34;&gt;# res accumulate with children&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;dfs(child, node, depth &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, children)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; res&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Pthread Memo</title>
      <link>https://example.org/posts/pthread-memo/</link>
      <pubDate>Wed, 28 May 2025 09:06:21 +0000</pubDate>
      <guid>https://example.org/posts/pthread-memo/</guid>
      <description>&lt;h1 id=&#34;feature&#34;&gt;Feature&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;shared memory&lt;/li&gt;&#xA;&lt;li&gt;using thread&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;compile&#34;&gt;Compile&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gcc -g -Wall -o pth_hello pth_hello.c -lpthread&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;// link the libaray&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;introduction-of-code&#34;&gt;Introduction of code&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;pthread.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;//global var, can be accessed by all the threads&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; thread_count;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Hello&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; rank); &lt;span style=&#34;color:#75715e&#34;&gt;//Function started by thread_create. Note this is the prototype, void* func_name(void* ...).&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; argc, &lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; argv[]) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;long&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt;;   &lt;span style=&#34;color:#75715e&#34;&gt;// use long in case of 64-bit system;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_t&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; thread_handles;  &lt;span style=&#34;color:#75715e&#34;&gt;// the identifier of each thread, readable by system, not user&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;thread_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;strtol&lt;/span&gt;(argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], NULL, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;); &lt;span style=&#34;color:#75715e&#34;&gt;// convert str to long, the last argument is base&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;thread_handles &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;malloc&lt;/span&gt;(thread_count&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_t&lt;/span&gt;));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; thread_count; &lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_create&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;thread_handles&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt;), NULL, Hello, (&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt;); &lt;span style=&#34;color:#75715e&#34;&gt;// 1st arg: p of thread handle, 2nd arg: not used, 3rd arg: func to start, 4th arg: arguments of func&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello from the main thread&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; thread_count; &lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;){&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&#x9;&lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_join&lt;/span&gt;(thread_handles[&lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt;], NULL);  &lt;span style=&#34;color:#75715e&#34;&gt;// finalize all the thread&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#a6e22e&#34;&gt;free&lt;/span&gt;(thread_handles);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Hello&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; rank) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;long&lt;/span&gt; my_rank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;long&lt;/span&gt;) rank;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello from thread %ld of %d&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, my_rank, thread_count); &lt;span style=&#34;color:#75715e&#34;&gt;// thread count is global variable here&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; NULL;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;api&#34;&gt;API&lt;/h1&gt;&#xA;&lt;h2 id=&#34;pthread_create&#34;&gt;pthread_create&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_create&lt;/span&gt;(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_t&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; thread_p, &lt;span style=&#34;color:#75715e&#34;&gt;//out, the thread handle, it will modify&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_attr_t&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; attr_p, &lt;span style=&#34;color:#75715e&#34;&gt;//in&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;start_routine)(&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;//in, the function to start&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; args_p, &lt;span style=&#34;color:#75715e&#34;&gt;//in the arguments&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;pthread_join&#34;&gt;pthread_join&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_join&lt;/span&gt;(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_t&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;thread&lt;/span&gt;, &lt;span style=&#34;color:#75715e&#34;&gt;//in&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; ret_val_p &lt;span style=&#34;color:#75715e&#34;&gt;//out, returned value from thread&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If not joining the thread, will lead to zombie thread, waste resources(stacks and local variables) and may prevent the creation of new threads. If program does not need to wait for a particular thread to finish, it can be detached with the pthread_detach function.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenMP Memo</title>
      <link>https://example.org/posts/openmp-memo/</link>
      <pubDate>Wed, 28 May 2025 09:06:20 +0000</pubDate>
      <guid>https://example.org/posts/openmp-memo/</guid>
      <description>&lt;h1 id=&#34;feature&#34;&gt;feature&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;shared-memory MIMD(Multi-Instruction Multi Data).&lt;/li&gt;&#xA;&lt;li&gt;Need support from the compiler&lt;/li&gt;&#xA;&lt;li&gt;simple to code (small change to serialized program)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;words&#34;&gt;words&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Directive-based shared memory: allows multiple processing units to access a common memory space using compiler &lt;strong&gt;directives&lt;/strong&gt;. It uses &lt;strong&gt;pragmas&lt;/strong&gt;(compiler hints). (If pragmas are supported, then it will be parallelized; otherwise, it will still be serialized.)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;header-apis&#34;&gt;Header APIs&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# pragma omp parallel num_threads(thread_count)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;Hello&lt;/span&gt;()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# You DO NOT have to specify how many threads should be here.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# It will utilize all the cores if you didn&amp;#39;t specify the number of cores.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# This comes from omp.h header file&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; my_rank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;omp_get_thread_num&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; thread_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;omp_get_num_threads&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;critical&#34;&gt;Critical&lt;/h2&gt;&#xA;&lt;p&gt;To avoid the race condition, when we aggregate values, we need critical directive&lt;/p&gt;</description>
    </item>
    <item>
      <title>MPI Memo</title>
      <link>https://example.org/posts/mpi-memo/</link>
      <pubDate>Wed, 28 May 2025 09:06:19 +0000</pubDate>
      <guid>https://example.org/posts/mpi-memo/</guid>
      <description>&lt;h1 id=&#34;compile--run&#34;&gt;Compile &amp;amp; Run&lt;/h1&gt;&#xA;&lt;p&gt;using a &lt;strong&gt;wrapper&lt;/strong&gt; for the C compiler.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mpicc -g -Wall -o mpi_hello mpi_hello.c&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;mpicc is a wrapper script, that telling c compiler where to find header file and what libraries should be linked.&lt;/p&gt;&#xA;&lt;p&gt;using mpiexec to run a mpi program&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mpiexec &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;n &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; .&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;mpi_hello&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;mpi&#34;&gt;MPI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;feature&#34;&gt;feature&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Distributed Memory&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;api&#34;&gt;API&lt;/h2&gt;&#xA;&lt;p&gt;These apis are included by &amp;lt;mpi.h&amp;gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;mpi_init&#34;&gt;MPI_Init&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;MPI_Init&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; argc_p, &lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;***&lt;/span&gt; argv_p);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;the parameter is pointer to argc and argv. If main(void), just pass NULL.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cuda Memo</title>
      <link>https://example.org/posts/cuda-memo/</link>
      <pubDate>Wed, 28 May 2025 09:06:17 +0000</pubDate>
      <guid>https://example.org/posts/cuda-memo/</guid>
      <description>&lt;h1 id=&#34;hello-world&#34;&gt;Hello world&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;cuda.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;/*Device code: runs on GPU*/&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Hello&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;) { &lt;span style=&#34;color:#75715e&#34;&gt;// always return type with void&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello from thread %d!&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, threadIdx.x);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;/*Host code: runs on CPU*/&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; argc, &lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; argv[]) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; thread_count;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;thread_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;strtol&lt;/span&gt;(argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], NULL, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;Hello &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, thread_count&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(); &lt;span style=&#34;color:#75715e&#34;&gt;// 1st arg specify how many SMs, 2nd arg specify how many SPs in each SMs. i.e. 1st arg specify the number of thread blocks. 2nd arg specifies the number of threads in each thread block.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#a6e22e&#34;&gt;cudaDeviceSynchronize&lt;/span&gt;();  &lt;span style=&#34;color:#75715e&#34;&gt;// this will cause main program to wait until all the threads have finished.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nvcc -o cuda_hello cuda_hello.cu&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./cuda_hello &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;build-in-variables&#34;&gt;Build-in variables&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;threadIdx: the rank or index of the thread in its thread blocks&lt;/li&gt;&#xA;&lt;li&gt;blockDim: the dimensions, shape, or size of the thread of blocks (how many thread in block)&lt;/li&gt;&#xA;&lt;li&gt;blockIdx: the rank or index of the block within the grid&lt;/li&gt;&#xA;&lt;li&gt;griddim: the dimensions, shape, or size of grid. (how many block in grid)&#xA;they all get fields x, y, and z&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; blk_ct, th_per_blk;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Hello &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;blk_ct, th_per_blk&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;//there gridDim.x = blk_ct, blockDim.x = th_per_blk&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;//if 3 dim,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;dim3 grid_dims, block_dims;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;grid_dims.x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;grid_dims.y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;grid_dims.z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;block_dims.x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;block_dims.y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;block_dims.z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Kenerl &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;grid_dims, block_dims&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;vec-add&#34;&gt;Vec-add&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Vec_add&lt;/span&gt;(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; x[], &lt;span style=&#34;color:#75715e&#34;&gt;//in&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; y[], &lt;span style=&#34;color:#75715e&#34;&gt;//in&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; z[],       &lt;span style=&#34;color:#75715e&#34;&gt;//out&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n &lt;span style=&#34;color:#75715e&#34;&gt;//in&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; my_elt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.x ;  &lt;span style=&#34;color:#75715e&#34;&gt;//important&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (my_elt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; n) &lt;span style=&#34;color:#75715e&#34;&gt;// global variable n&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#x9;&#x9;z[my_elt] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x[my_elt] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; y[my_elt];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;key idea: assign the iterations of a loop to a individual threads&lt;/p&gt;</description>
    </item>
    <item>
      <title>Code Memo</title>
      <link>https://example.org/posts/code-memo/</link>
      <pubDate>Wed, 28 May 2025 09:06:15 +0000</pubDate>
      <guid>https://example.org/posts/code-memo/</guid>
      <description>&lt;h1 id=&#34;mpi&#34;&gt;MPI&lt;/h1&gt;&#xA;&lt;p&gt;broadcast k, and n&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;MPI_Bcast&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;k, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, MPI_INT, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, comm); &lt;span style=&#34;color:#75715e&#34;&gt;// or MPI_COMM_WORLD&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;MPI_Bcast&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;n, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, MPI_INT, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, comm); &lt;span style=&#34;color:#75715e&#34;&gt;// or MPI_COMM_WORLD&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;set num_of_reads_local&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;num_of_reads_local &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; num_process;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;allocate csr displs and csr offs&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; readCSR_displs[MAX_PROCESS&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], readCSR_counts[MAX_PROCESS&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; readCSRoffs_displs[MAX_PROCESS&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],readCSRoffs_counts[MAX_PROCESS&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;MPI_Bcast&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;max_readCSR_size_local, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, MPI_INT, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, comm);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;MPI_Bcast&lt;/span&gt;(readCSR_counts, num_process, MPI_INT, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, comm);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;MPI_Bcast&lt;/span&gt;(readCSRoffs_counts, num_process, MPI_INT, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, comm);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;copy data&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;num_of_read_local_p0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; num_of_reads_local &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (num_process &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;readCSRoffs_displs[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; readCSRoffs_displs[i&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; num_process;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;readCSR_displs[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; reads_CSR_offs[readCSRoffs_displs[i]];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;readCSR_counts[i&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; readCSR_displs[i] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; readCSR_displs[i&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;readCSRoffs_counts[i&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; readCSRoffs_displs[i] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; readCSRoffs_displs[i&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;reads_CSR_local &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new &lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt;[max_readCSR_size_local&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;];&lt;span style=&#34;color:#75715e&#34;&gt;//&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;reads_CSR_offs_local &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;[num_of_reads_local&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;];&lt;span style=&#34;color:#75715e&#34;&gt;//&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;generate universal minimizer&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;um_lists_local.&lt;span style=&#34;color:#a6e22e&#34;&gt;push_back&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;generate_universal_minimizer_list&lt;/span&gt;(k, reads_CSR_offs_local[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; reads_CSR_offs_local[i], reads_CSR_local &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; reads_CSR_offs_local[i]));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;process modified offset array&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lazyvim-Memo</title>
      <link>https://example.org/posts/lazyvim-memo/</link>
      <pubDate>Fri, 23 May 2025 12:07:09 +0000</pubDate>
      <guid>https://example.org/posts/lazyvim-memo/</guid>
      <description>&lt;p&gt;I come across an error when I tried to use nvim in iterm2(set to a background).&#xA;The down side of termnial start to wink when using nvim.&#xA;The error is fixed by changing the nvim background to transparent.&lt;/p&gt;&#xA;&lt;p&gt;add a new file in ~/.config/nvim/lua/plugins/colorscheme.lua&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;return {&#xA;{&#xA;  &amp;#34;folke/tokyonight.nvim&amp;#34;,&#xA;  opts = {&#xA;    transparent = true,&#xA;    styles = {&#xA;      sidebars = &amp;#34;transparent&amp;#34;,&#xA;      floats = &amp;#34;transparent&amp;#34;,&#xA;    },&#xA;  },&#xA;},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;note&#34;&gt;Note:&lt;/h2&gt;&#xA;&lt;p&gt;Actually, it doesn&amp;rsquo;t work at all.&#xA;Fixed by dragging the little bar down side to the bottom.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Zathura</title>
      <link>https://example.org/posts/zathura/</link>
      <pubDate>Fri, 23 May 2025 08:47:59 +0000</pubDate>
      <guid>https://example.org/posts/zathura/</guid>
      <description>&lt;p&gt;first, tap this repo and install:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew tap homebrew-zathura/zathura&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew install zathura&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;install some plugins:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew install zathura-djvu zathura-pdf-mupdf zathura-ps&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After you install all required plugins you need to put them in a directory where zathura can find them. To do this, run the following command. You have to run this command only after installing new plugins.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;brew --prefix zathura&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;/lib/zathura ; mkdir -p $d ; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n in cb djvu pdf-mupdf pdf-poppler ps ; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;brew --prefix zathura-$n&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;/lib$n.dylib ; &lt;span style=&#34;color:#f92672&#34;&gt;[[&lt;/span&gt; -f $p &lt;span style=&#34;color:#f92672&#34;&gt;]]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ln -s $p $d ; &lt;span style=&#34;color:#66d9ef&#34;&gt;done&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To use zathura as macOS application, run following command. You have to run this command each time you&amp;rsquo;re installing new plugins to update bundle info.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tmux-Memo</title>
      <link>https://example.org/posts/tmux-memo/</link>
      <pubDate>Thu, 22 May 2025 17:30:53 +0000</pubDate>
      <guid>https://example.org/posts/tmux-memo/</guid>
      <description>&lt;ul&gt;&#xA;&lt;li&gt;C-b &amp;quot; split vertical&lt;/li&gt;&#xA;&lt;li&gt;C-b % split ..&lt;/li&gt;&#xA;&lt;li&gt;C-b x delete&lt;/li&gt;&#xA;&lt;li&gt;C-b w show all the window&lt;/li&gt;&#xA;&lt;li&gt;C-b [ get into vim mode&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Yabai-Memo</title>
      <link>https://example.org/posts/yabai-memo/</link>
      <pubDate>Thu, 22 May 2025 17:17:45 +0000</pubDate>
      <guid>https://example.org/posts/yabai-memo/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew install koekeishiya/formulae/yabai&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;yabai --start-service&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;yabai 是软件本体 brew 安装&#xA;skhd是配套的快捷键编辑器&#xA;spacebar 还没研究&lt;/p&gt;&#xA;&lt;p&gt;rong&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vscode-Memo</title>
      <link>https://example.org/posts/vscode-memo/</link>
      <pubDate>Thu, 22 May 2025 17:17:43 +0000</pubDate>
      <guid>https://example.org/posts/vscode-memo/</guid>
      <description>&lt;p&gt;Open vscode in terminal with reusing the current window:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;code -r .&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;-r stand for reuse.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Iterm-Memo</title>
      <link>https://example.org/posts/iterm-memo/</link>
      <pubDate>Thu, 22 May 2025 17:17:36 +0000</pubDate>
      <guid>https://example.org/posts/iterm-memo/</guid>
      <description>&lt;p&gt;install nerd font using brew:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew install --cask font-fira-code-nerd-fon&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;cmd + , to open iterm setting.&#xA;change the profile -&amp;gt; text -&amp;gt; font -&amp;gt; non asiic font.&lt;/p&gt;</description>
    </item>
    <item>
      <title>pyspark memo</title>
      <link>https://example.org/posts/pyspark/pyspark-memo/</link>
      <pubDate>Mon, 19 May 2025 09:30:16 +0000</pubDate>
      <guid>https://example.org/posts/pyspark/pyspark-memo/</guid>
      <description>&lt;h1 id=&#34;classic-staring-code&#34;&gt;Classic Staring Code&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SparkContext, SparkConf&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkConf()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setAppName(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;conf&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setMaster(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local[*]&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# to use spark, SparkContext is necessary.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkContext(conf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;conf)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelized(data, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# or you can read from file (hdfs, file, ...)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;textFile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;README.md&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# no materialization so far.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;transformations&#34;&gt;Transformations&lt;/h1&gt;&#xA;&lt;h2 id=&#34;typical-one&#34;&gt;typical one&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;map&lt;/li&gt;&#xA;&lt;li&gt;filter&lt;/li&gt;&#xA;&lt;li&gt;distince&lt;/li&gt;&#xA;&lt;li&gt;flatMap&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# flatMap will flap list.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: [x, x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: list(x))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; [{&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;}, {&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;}] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# transformation, so all not materialized.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;key-value-transformation&#34;&gt;key-value transformation&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;reduceByKey&lt;/li&gt;&#xA;&lt;li&gt;sortByKey&lt;/li&gt;&#xA;&lt;li&gt;groupByKey&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduceByKey(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; a, b: a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; [(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# sort by keys &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sortByKey()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; [(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupByKey()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; [(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, [&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]), (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;other&#34;&gt;other&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;mapValues&lt;/li&gt;&#xA;&lt;li&gt;sortBy&lt;/li&gt;&#xA;&lt;li&gt;join&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupByKey()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mapValues(sum)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# False for desending, True for ascending&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sortBy(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(other_rdd, rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;id &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; other_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uid)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;actions&#34;&gt;Actions&lt;/h1&gt;&#xA;&lt;p&gt;reduce (commutative and associative)&#xA;take&#xA;collect&#xA;takeOrdered(n, key=func)&#xA;count&#xA;isEmpty&#xA;treeReduce(Reduces the elements of this RDD in a multi-level tree pattern. faster than normal one)&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://example.org/posts/hugo/hugo-bugs/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/hugo/hugo-bugs/</guid>
      <description>&lt;h1 id=&#34;bug-list&#34;&gt;Bug list&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;draft not true&lt;/li&gt;&#xA;&lt;li&gt;date is in future&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>5002 Association Memo</title>
      <link>https://example.org/posts/5002/5002-association-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-association-memo/</guid>
      <description>&lt;h1 id=&#34;basic-concept&#34;&gt;Basic concept&lt;/h1&gt;&#xA;&lt;p&gt;The support of itemset of different size like:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;itemset-size1 :{B}&lt;/li&gt;&#xA;&lt;li&gt;itemset-size2: {A, B}&#xA;supp({B}) = count of apparence of B. &amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Association rule: {A, B} -&amp;gt; C&#xA;support of associaiton rule: supp({A, B}-&amp;gt;C) = supp({A, B, C})&#xA;confidence of association rule: conf({A, B}-&amp;gt;C) = supp({A, B, C}) / supp({A, B})&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Bayesian Classifier Memo</title>
      <link>https://example.org/posts/5002/5002-bayesian-classifier-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-bayesian-classifier-memo/</guid>
      <description>&lt;h1 id=&#34;conditional-probability&#34;&gt;Conditional Probability&lt;/h1&gt;&#xA;&lt;p&gt;$P(B | A) = \frac {P(A | B) P(B)} {P(A)}$&#xA;Assuming x, y, z are independent, we have:&#xA;$P(x, y, z | A) = P(x | A) + P(y | A) + P(z | A)$&lt;/p&gt;&#xA;&lt;h1 id=&#34;naive-bayesian-classifier&#34;&gt;Naive Bayesian Classifier&lt;/h1&gt;&#xA;&lt;p&gt;Assume all the attribute are independent, and we get:&#xA;$$\begin{align}&#xA;P(yes | race, income) &amp;amp;= \frac {P(race, income | yes) P(yes)} {P(race, income)} \&#xA;&amp;amp;= \frac {P(race | yes) P(income | yes) P(yes)} {P(race, income)}&#xA;\end{align}$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Data Stream Memo</title>
      <link>https://example.org/posts/5002/5002-data-stream-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-data-stream-memo/</guid>
      <description>&lt;h1 id=&#34;ideas&#34;&gt;Ideas&lt;/h1&gt;&#xA;&lt;h2 id=&#34;epsilon-deficient-synopsis&#34;&gt;$\epsilon$-deficient synopsis&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Condition 1: There is no false negative (true one wil be true)&lt;/li&gt;&#xA;&lt;li&gt;The difference between estimated and true is at most $\epsilon$N.(error rate)&lt;/li&gt;&#xA;&lt;li&gt;True frequencies less than (s-$\epsilon$)N are classified as infrequent (the most error one are still infrequent)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;kind&#34;&gt;Kind&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sticky Sampling Algorithm&lt;/li&gt;&#xA;&lt;li&gt;Lossy Counting Algorithm&lt;/li&gt;&#xA;&lt;li&gt;Space-Saving Algorithm&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;sticky-sampling-algorithm&#34;&gt;Sticky Sampling Algorithm&lt;/h1&gt;&#xA;&lt;h2 id=&#34;properties&#34;&gt;properties&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;using probability&lt;/li&gt;&#xA;&lt;li&gt;has confidence parameter $\delta$ (how confident your result is)&lt;/li&gt;&#xA;&lt;li&gt;support threshold s and error parameter $\epsilon$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;bucket-design&#34;&gt;bucket design&lt;/h2&gt;&#xA;&lt;p&gt;$t = \lceil 1/ \epsilon ln(s^{-1}\sigma^{-1})\rceil$ (decide the size of each bucket)&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Decision Tree Memo</title>
      <link>https://example.org/posts/5002/5002-decision-tree-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-decision-tree-memo/</guid>
      <description>&lt;h1 id=&#34;type-of-decision-tree&#34;&gt;Type of Decision Tree&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ID3&#xA;Information gain&lt;/li&gt;&#xA;&lt;li&gt;C4.5&#xA;Information gain normalized by entropy(split info).&lt;/li&gt;&#xA;&lt;li&gt;CART&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;entropy&#34;&gt;Entropy&lt;/h1&gt;&#xA;&lt;p&gt;To measure how informative a distribution is.&#xA;The formula is as follows:&#xA;$\text{Entropy} = - \sum p log p$&#xA;Here, the logarithm is based on a base of two.&#xA;The greater the entropy is, the less informative the distribution is.&#xA;For example:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;P(tail) = 0.5  P(tail) = 0.5  entropy = 1&#xA;P(tail) = 1    P(tail) = 0    entropy = &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;We assume 0log 0 = 0 in the calculation&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Hierarchical Clustering Memo</title>
      <link>https://example.org/posts/5002/5002-hierarchical-clustering/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-hierarchical-clustering/</guid>
      <description>&lt;h1 id=&#34;kinds&#34;&gt;Kinds&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Agglomerative methods&#xA;It begin from clusters based on each data point to a big cluster containing all the data point&lt;/li&gt;&#xA;&lt;li&gt;Divisive Methods&#xA;From big cluster containing all the data point to cluster containing one data point.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;dendrogram&#34;&gt;Dendrogram&lt;/h1&gt;&#xA;&lt;p&gt;![[Pasted image 20250516131649.png]]&lt;/p&gt;&#xA;&lt;h1 id=&#34;distance&#34;&gt;Distance&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Single Linkage: The nearest distance between two point in two cluster&lt;/li&gt;&#xA;&lt;li&gt;Complete Linkage: The distance between two cluster is given by the distance between their most distant members&lt;/li&gt;&#xA;&lt;li&gt;Group Average Linkage: The average of the distance between all pairs of records (pair-wise)&lt;/li&gt;&#xA;&lt;li&gt;Centroid Linkage: The distance is defined as the distance between the mean vector of two cluster&lt;/li&gt;&#xA;&lt;li&gt;Median Linkage: The mid-point of the original two cluster cetnres is used as the centre of the new combined group. To avoid the characteristic properties of the small one are lost.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;bottom-upagglomerative&#34;&gt;Bottom-up(Agglomerative)&lt;/h1&gt;&#xA;&lt;p&gt;![[Pasted image 20250516133344.png]]&#xA;&lt;strong&gt;single linkage:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 K-means Clustering Memo</title>
      <link>https://example.org/posts/5002/5002-k-means-clustering/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-k-means-clustering/</guid>
      <description>&lt;h1 id=&#34;k-means&#34;&gt;K-means&lt;/h1&gt;&#xA;&lt;p&gt;First, we get a pre-defined parameter k.&#xA;We make k random guesses of the mean point.&#xA;Do iterations until the mean doesn&amp;rsquo;t change.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Assign each data point to the cluster whose mean is nearest&lt;/li&gt;&#xA;&lt;li&gt;Calculate the mean of each cluster&lt;/li&gt;&#xA;&lt;li&gt;Replace the cluster with a new mean&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;about-the-initialization-of-k-means&#34;&gt;About the initialization of k-means&lt;/h2&gt;&#xA;&lt;p&gt;The popular way to initialize the starting mean is a random choice.&#xA;The result depends on the initial guess, and a suboptimal result is possible, so we do several different starting points.&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Neural Network Memo</title>
      <link>https://example.org/posts/5002/5002-neural-network/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-neural-network/</guid>
      <description>&lt;h1 id=&#34;activation-function&#34;&gt;Activation Function&lt;/h1&gt;&#xA;&lt;h2 id=&#34;threshold-function-step-function-hard-limiter&#34;&gt;Threshold function, Step function, Hard Limiter&lt;/h2&gt;&#xA;&lt;p&gt;$$&#xA;y = \begin{cases}&#xA;1 \quad \text{if net } \geq 0\&#xA;0 \quad \text{if net } &amp;lt; 0&#xA;\end{cases}&#xA;$$&lt;/p&gt;&#xA;&lt;h2 id=&#34;linear-function&#34;&gt;Linear Function&lt;/h2&gt;&#xA;&lt;p&gt;Just Identiy Function&lt;/p&gt;&#xA;&lt;h1 id=&#34;rectifier-function--rectified-linear-unitrelu&#34;&gt;Rectifier Function / Rectified Linear Unit(ReLU)&lt;/h1&gt;&#xA;&lt;p&gt;$$&#xA;y = \begin{cases}&#xA;net \quad \text{if net } \geq 0\&#xA;0 \quad \text{if net } &amp;lt; 0&#xA;\end{cases}&#xA;$$&lt;/p&gt;&#xA;&lt;h1 id=&#34;sigmoid-function&#34;&gt;Sigmoid Function&lt;/h1&gt;&#xA;&lt;p&gt;![[Pasted image 20250515160346.png]]&lt;/p&gt;&#xA;&lt;h1 id=&#34;tanh-function&#34;&gt;tanh Function&lt;/h1&gt;&#xA;&lt;p&gt;![[Pasted image 20250515160408.png]]&lt;/p&gt;&#xA;&lt;h2 id=&#34;forwardsingle-neuron&#34;&gt;Forward(single neuron)&lt;/h2&gt;&#xA;&lt;p&gt;$\text{net} = w_1x_1 + w_2x_2 + b$&#xA;$y = \frac{1}{1 + e^{-net}}$&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Other Clustering Memo</title>
      <link>https://example.org/posts/5002/5002-other-clustering-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-other-clustering-memo/</guid>
      <description>&lt;h1 id=&#34;methods&#34;&gt;Methods&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Model-Based Clustering (EM algorithm)&lt;/li&gt;&#xA;&lt;li&gt;Density-Based Clustering (DBSCAN)&lt;/li&gt;&#xA;&lt;li&gt;Scalable Clustering Method (BIRCH)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;em-algorithm&#34;&gt;EM algorithm&lt;/h1&gt;&#xA;&lt;h2 id=&#34;why&#34;&gt;why?&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;previous method, each point belongs to a single cluster. No point belongs to different cluster with probabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;normal-distribution&#34;&gt;Normal distribution&lt;/h2&gt;&#xA;&lt;p&gt;$p(x|&amp;lt;\mu, \sigma&amp;gt;)=\frac{1}{\sqrt{2\pi}\sigma}e^{- \frac{(x-\mu)^2}{2\sigma^2}}$&#xA;sigma = standard derivation, mu = mean.&lt;/p&gt;&#xA;&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Initialize all $\mu_i$ and $\sigma_i$ (random)&lt;/li&gt;&#xA;&lt;li&gt;For each point x, we calculate its probability belong to cluster i. (formula: $p(x\in C_i) = \frac{p(x|&amp;lt;\mu_i, \sigma_i&amp;gt;)} { \sum p(x|&amp;lt;\mu, \sigma&amp;gt;})$, i.e. probability of cluster i divided by the sum of probability of all the clusters)&lt;/li&gt;&#xA;&lt;li&gt;We calculate the new mean of cluster, and update $\mu$. using formula($\mu_i = \sum_{X} x \frac{p(x\in C_i)}{\sum_y p(y\in C_i)}$. (i.e. according to the probabilities that all points belong to cluster i)&#xA;Repeat until converge&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;dbscan&#34;&gt;DBSCAN&lt;/h1&gt;&#xA;&lt;h2 id=&#34;why-1&#34;&gt;why?&lt;/h2&gt;&#xA;&lt;p&gt;traditional clustering cannot handle irregular shaped cluster&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Outlier Memo</title>
      <link>https://example.org/posts/5002/5002-outlier-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-outlier-memo/</guid>
      <description>&lt;h1 id=&#34;comparison&#34;&gt;Comparison&lt;/h1&gt;&#xA;&lt;p&gt;Statistical Model Disadv: Assume that the data follows a particular distribution.&#xA;Distance-based Model Adv: No assume distribution. But not density wise.&#xA;Density-Based Model Adv: can find local outliers&lt;/p&gt;&#xA;&lt;h1 id=&#34;concept&#34;&gt;Concept&lt;/h1&gt;&#xA;&lt;p&gt;$\epsilon$ is the distance between p and the k-th nearest neighbor.&#xA;local reachability density lrd_k(p) is: $\frac 1 \epsilon$&#xA;local outlier factor(LOF) is $(\sum_{o \in N_k(p)} \frac{lrd_k(o)}{lrd_k(p)})/{k}$&#xA;N_k(p) is the $\epsilon$-neighborhood of p (excluding p).&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Recurrent Neural Network Memo</title>
      <link>https://example.org/posts/5002/5002-recurrent-neural-network-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-recurrent-neural-network-memo/</guid>
      <description>&lt;h1 id=&#34;difference-with-neural-network&#34;&gt;Difference with Neural Network&lt;/h1&gt;&#xA;&lt;p&gt;The output of RNN are passed to the next RNN network (internal variable).&lt;/p&gt;&#xA;&lt;h1 id=&#34;multilayer&#34;&gt;Multilayer&lt;/h1&gt;&#xA;&lt;p&gt;Actually, these rnn can have multiple layers and multiple memory units.&lt;/p&gt;&#xA;&lt;h1 id=&#34;basic-rnn&#34;&gt;Basic RNN&lt;/h1&gt;&#xA;&lt;p&gt;The basic rnn is simple. It use internal variable(s) as output variable(y). And the s can be calculated by using:&#xA;$s_t = tanh(W [x_{t}, s_{t-1}] + b)$&#xA;$y_t = s_t$&lt;/p&gt;&#xA;&lt;h1 id=&#34;lstm&#34;&gt;LSTM&lt;/h1&gt;&#xA;&lt;p&gt;There are components:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;internal variable to store memory&lt;/li&gt;&#xA;&lt;li&gt;forget feature to forget some portion of internal variable&lt;/li&gt;&#xA;&lt;li&gt;input feature to decide portion of input and strength of input&lt;/li&gt;&#xA;&lt;li&gt;output feature to decide portion of output and strength of output&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;some-significant-difference&#34;&gt;Some significant difference&lt;/h2&gt;&#xA;&lt;p&gt;First, the output and internal state previous are input, too.&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Subspace clustering Memo</title>
      <link>https://example.org/posts/5002/5002-subspace-clustering-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-subspace-clustering-memo/</guid>
      <description>&lt;h1 id=&#34;methods&#34;&gt;Methods&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Dense Unit-based Method&lt;/li&gt;&#xA;&lt;li&gt;Entropy-Based Method&lt;/li&gt;&#xA;&lt;li&gt;Transformation-Based Method&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;why-subspace-clustering&#34;&gt;why subspace clustering?&lt;/h2&gt;&#xA;&lt;p&gt;dimension curse: when the number of dimensions increases, the distance between any two points is nearly the same.&lt;/p&gt;&#xA;&lt;h1 id=&#34;dense-unit-based-method&#34;&gt;Dense Unit-based Method&lt;/h1&gt;&#xA;&lt;h2 id=&#34;property&#34;&gt;Property&lt;/h2&gt;&#xA;&lt;p&gt;If a set is cluster in k dimension, then it&amp;rsquo;s part of cluster in k-1 dimension, too.&lt;/p&gt;&#xA;&lt;h2 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Identify sub-space that contain dense units (aprior algorithm, find x, y, z these dimension)&lt;/li&gt;&#xA;&lt;li&gt;Identify clusters in each sub-space that contain dense units (base on previous found x, y, z dimension, we find cluster like {x:[1, 10] y: [11, 20]}, etc..)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;adapt-aprior&#34;&gt;adapt aprior&lt;/h2&gt;&#xA;&lt;p&gt;for example, we get grid of 10, and mark $X_1$ as [1, 10], and so on. threshold 1.&#xA;( 1, 19) $X_0$ $Y_1$&#xA;(11, 29) $X_1$ $Y_2$&#xA;(21, 39) $X_2$ $Y_3$&#xA;(31, 49) $X_3$ $Y_4$&#xA;(41, 59) $X_4$ $Y_5$&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 SVM Memo</title>
      <link>https://example.org/posts/5002/5002-svm-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-svm-memo/</guid>
      <description>&lt;h1 id=&#34;linear-support-vector-machine&#34;&gt;Linear Support Vector Machine&lt;/h1&gt;&#xA;&lt;p&gt;We can generalize this problem as this:&#xA;$$&#xA;\begin{align}&#xA;\min w_1^2 + w_2^2 \&#xA;\text{subject to } y(w_1x_1+w_2x_2+b) \geq 1&#xA;\end{align}&#xA;$$&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-minimizing-this-term&#34;&gt;Why minimizing this term?&lt;/h2&gt;&#xA;&lt;p&gt;Because we want to maximize the distance D between two line. The D is involved in w by $\frac{w}{D}$.&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-transform-maximizing-to-minimizing&#34;&gt;Why transform maximizing to minimizing?&lt;/h2&gt;&#xA;&lt;p&gt;We want to transform the objective function from a non-linear form to a quadratic form.&lt;br&gt;&#xA;Then, the problem becomes a form of quadratic programming which has many existing efficient techniques for that.&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Web Database Memo</title>
      <link>https://example.org/posts/5002/5002-web-database-memo/</link>
      <pubDate>Fri, 16 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-web-database-memo/</guid>
      <description>&lt;p&gt;Authority weight (in-degree)&#xA;Hub weight (out-degree)&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A good authority has many edges from good hubs&lt;/li&gt;&#xA;&lt;li&gt;A good hub has many edges from good authorities&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;hit-algorithm&#34;&gt;Hit Algorithm&lt;/h1&gt;&#xA;&lt;p&gt;Two steps:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sampling Step&lt;/li&gt;&#xA;&lt;li&gt;Iteration Step&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;sampling-step&#34;&gt;sampling step&lt;/h2&gt;&#xA;&lt;p&gt;Given a user query with several terms, we collect a set of pages that are very relevant &amp;ndash; called the base set.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;We get all the web page that contain any query terms. This is called root set.&lt;/li&gt;&#xA;&lt;li&gt;We find the link pages, which are linked by or link to web pages of root set.&lt;/li&gt;&#xA;&lt;li&gt;Base set = link pages &amp;amp; root set&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;iteration-step&#34;&gt;Iteration Step&lt;/h2&gt;&#xA;&lt;p&gt;We know the hub weight of a web page is given by:&#xA;$h(N) = a(N) + a(MS) + a(A)$&#xA;etc..&#xA;so we can get:&#xA;$\vec{h} = [{h(N), h(MS), h(A)}]$&#xA;$\vec{a} = [{a(N), a(MS), a(A)}]$&#xA;$\vec{h} = M\vec{a}$&#xA;Here M represents adjacent matrix.&lt;/p&gt;</description>
    </item>
    <item>
      <title>5002 Data Warehouse Memo</title>
      <link>https://example.org/posts/5002/5002-memo-data-warehouse/</link>
      <pubDate>Wed, 14 May 2025 17:10:29 +0800</pubDate>
      <guid>https://example.org/posts/5002/5002-memo-data-warehouse/</guid>
      <description>&lt;h1 id=&#34;whats-data-warehouse&#34;&gt;What&amp;rsquo;s Data warehouse&lt;/h1&gt;&#xA;&lt;p&gt;Suppose there are two queries.&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;select all the UST students coming from HK.&#xA;select all the UST students coming from Mainland.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;They are complicate query, and could cost for one day.&#xA;So we can store our pre-computed results.&#xA;This is Data Warehouse&amp;ndash;pre-computed results.&lt;/p&gt;&#xA;&lt;p&gt;User ask database, data warehouse could response without querying database.&lt;/p&gt;&#xA;&lt;h1 id=&#34;basic-ideas-about-how-to-build-warehouse&#34;&gt;Basic Ideas about how to build warehouse.&lt;/h1&gt;&#xA;&lt;p&gt;We know clearly that we there are query related to grouping or agregating. So we can build our warehouse according to these group.&#xA;Suppose there are table containing three different columns&amp;ndash; p, c, s.&#xA;we can mark a group by with p, c, s as pcs. And a group with c, s as cs, so on so forth.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PySpark Memo 4</title>
      <link>https://example.org/posts/pyspark/pyspark-memo-4/</link>
      <pubDate>Wed, 07 May 2025 16:55:33 +0800</pubDate>
      <guid>https://example.org/posts/pyspark/pyspark-memo-4/</guid>
      <description>&lt;h1 id=&#34;chapter-2&#34;&gt;Chapter 2&lt;/h1&gt;&#xA;&lt;h1 id=&#34;content&#34;&gt;Content&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Aggregate And GroupBy&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;codes&#34;&gt;Codes:&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SparkSession&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkSession&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;appName(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;DataFrame&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getOrCreate()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;, header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, inferSchema&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# You can do groupby and then aggregate.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# You get 2 different way to do aggreate.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# where the aggregator, i.e. sum gives you a dataframe.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupBy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupBy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupBy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;avg()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupBy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Another way to do aggregate:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;agg({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Salary&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;})&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>PySpark Memo 3</title>
      <link>https://example.org/posts/pyspark/pyspark-memo-3/</link>
      <pubDate>Wed, 07 May 2025 01:31:22 +0800</pubDate>
      <guid>https://example.org/posts/pyspark/pyspark-memo-3/</guid>
      <description>&lt;h1 id=&#34;chapter-2&#34;&gt;Chapter 2&lt;/h1&gt;&#xA;&lt;h1 id=&#34;content&#34;&gt;Content&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Filter Operation&lt;/li&gt;&#xA;&lt;li&gt;including: &amp;amp;, |, ==, ~&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;codes&#34;&gt;Codes:&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SparkSession&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkSession&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;appName(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;DataFrame&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getOrCreate()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;, header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, inferSchema&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# filter first format:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Salary&amp;lt;=2000&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# filter second format:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(df_spark[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Salary&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# filter and&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter((df_spark[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Salary&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; (df_spark[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Salary&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1500&lt;/span&gt;))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# you can use or as |&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# filter ~ is also the same&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>PySpark Memo 2</title>
      <link>https://example.org/posts/pyspark/pyspark-memo-2/</link>
      <pubDate>Wed, 07 May 2025 01:16:44 +0800</pubDate>
      <guid>https://example.org/posts/pyspark/pyspark-memo-2/</guid>
      <description>&lt;h1 id=&#34;chapter-2&#34;&gt;Chapter 2&lt;/h1&gt;&#xA;&lt;h1 id=&#34;content&#34;&gt;Content&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Dropping Columns&lt;/li&gt;&#xA;&lt;li&gt;Dropping Rows&lt;/li&gt;&#xA;&lt;li&gt;Various Parameter In Dropping functionalities&lt;/li&gt;&#xA;&lt;li&gt;Handling Missing values by Mean, Median and Mode&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;codes&#34;&gt;Codes:&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SparkSession&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkSession&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;appName(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;DataFrame&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getOrCreate()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;, header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, inferSchema&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;na&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# This is default way of na.drop, any.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;na&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;any&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#39;all&amp;#39; will trop those containing every feature as na&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;na&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;all&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# You can add threshold, those get at least 2 non-na will remain.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;na&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;any&amp;#39;&lt;/span&gt;, threshold&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# You can use subset to limit the view from whole to a little subset, so that you can use threshold or &amp;#39;how&amp;#39; or flexible&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;na&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;any&amp;#39;&lt;/span&gt;, subset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# so you can fill in the na, too&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# you provide fill(value_to_fill, columns_to_select)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;na&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fill(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Missing Values&amp;#39;&lt;/span&gt;, [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Experience&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#You can use MLlib, too&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.ml.feature &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Imputer&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;imputer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Imputer(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;inputCols&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Experience&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Salary&amp;#39;&lt;/span&gt;],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;outputCols&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;_imputed&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(c) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Experience&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Salary&amp;#39;&lt;/span&gt;]]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setStrategy(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;median&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;imputer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(df_pyspark)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(df_spark)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>pyspark memo</title>
      <link>https://example.org/posts/pyspark/pyspark-memo2/</link>
      <pubDate>Tue, 06 May 2025 21:17:29 +0800</pubDate>
      <guid>https://example.org/posts/pyspark/pyspark-memo2/</guid>
      <description>&lt;h1 id=&#34;chapter-1&#34;&gt;Chapter 1&lt;/h1&gt;&#xA;&lt;h1 id=&#34;content&#34;&gt;Content&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PySpark Datafram&lt;/li&gt;&#xA;&lt;li&gt;Reading The Dataset&lt;/li&gt;&#xA;&lt;li&gt;Checking the Datatype of the Column(Schema)&lt;/li&gt;&#xA;&lt;li&gt;Selecting Columns And indexing&lt;/li&gt;&#xA;&lt;li&gt;Check Describe option similar to Pandas&lt;/li&gt;&#xA;&lt;li&gt;Adding Columns&lt;/li&gt;&#xA;&lt;li&gt;Droping Columns&lt;/li&gt;&#xA;&lt;li&gt;Renaming Columns&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;codes&#34;&gt;Codes:&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyspark.sql &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SparkSession&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# To use spark dataframe, we need session first&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SparkSession&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;builder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;appName(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;DataFrame&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getOrCreate()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# This read will not infer header and the types&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#or you can use read option(k, v)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;option(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;header&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;true&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#And if you want to use something like auto casting, you can add inferSchema&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;option(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;header&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;true&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;, inferSchema&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# check your schema&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;printSchema()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; root&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;|--&lt;/span&gt; Name: string (nullable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;|--&lt;/span&gt; age: integer (nullable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;|--&lt;/span&gt; Experience: integer (nullable &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; true)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#You can do the read this way, too.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test.csv&amp;#39;&lt;/span&gt;, header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, inferSchema&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+---------+---+----------+&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;     Name&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;age&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;Experience&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+---------+---+----------+&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;    Krish&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;Sudhanshu&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;         &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;    Sunny&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;         &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+---------+---+----------+&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# if you want to select some columns&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;select(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;select([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Experience&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#The select will return you dataframe by the way.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# If you want just a column, you can do this.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; Column&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# and like in pandas, there are &amp;#39;describe&amp;#39;, which can help you to print the statistics of your data. by the way, describe returns you a dataframe. &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# So how can you replace, adding or *renaming columns?&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# This is adding new columns. And it is not in-place.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;withColumn(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Experience After 2 year&amp;#39;&lt;/span&gt;, df_spark[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Experience&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# You can drop, not in-place, too.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Experinece After 2 year&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# You can rename&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df_spark &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df_spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;withColumnRenamed(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;New Name&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Python Cookbook Memo</title>
      <link>https://example.org/posts/python/python-cookbook-memo/</link>
      <pubDate>Tue, 06 May 2025 16:58:38 +0800</pubDate>
      <guid>https://example.org/posts/python/python-cookbook-memo/</guid>
      <description>&lt;h1 id=&#34;31-round-of-numbers&#34;&gt;3.1 round of numbers&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;round(num, n_digit)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;1.23&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.2&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;1.77&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.8&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;However, something like 1.5 or 2.5, it will return you the nearest even number. Here, it shoulb be 2.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;round(&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.0&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;n_digit can be negative, too. It will handle the digit before the decimal point.&lt;/p&gt;&#xA;&lt;h1 id=&#34;32-accurate-decimal-arithmetic&#34;&gt;3.2 Accurate Decimal Arithmetic&lt;/h1&gt;&#xA;&lt;p&gt;If you want more accurate arithmetic, do this:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; decimal &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Decimal&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Decimal(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;4.2&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Decimal(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2.1&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; Decimal(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;6.3&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And if you want to control the precision of your computation, you can use context like this:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Workflow</title>
      <link>https://example.org/posts/hugo/workflow/</link>
      <pubDate>Tue, 29 Apr 2025 01:50:25 +0800</pubDate>
      <guid>https://example.org/posts/hugo/workflow/</guid>
      <description>&lt;ul&gt;&#xA;&lt;li&gt;first you need new a markdown using hugo.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hugo new posts/new.md&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;after that, you can edit this markdown anyway.&lt;/li&gt;&#xA;&lt;li&gt;change the status: draft to false.&lt;/li&gt;&#xA;&lt;li&gt;then you can check the updated site by:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;if you need to see with draft:&#xA;hugo server -D &#xA;no draft:&#xA;hugo server&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;git add and commit then push.&lt;/li&gt;&#xA;&lt;li&gt;see the new site using url:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;https://shawrong.github.io&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;rong shuo&lt;/p&gt;</description>
    </item>
    <item>
      <title>Workflow</title>
      <link>https://example.org/posts/pyspark/pyspark_useful/</link>
      <pubDate>Tue, 29 Apr 2025 01:50:25 +0800</pubDate>
      <guid>https://example.org/posts/pyspark/pyspark_useful/</guid>
      <description>&lt;p&gt;map&lt;/p&gt;&#xA;&lt;p&gt;flatmap&lt;/p&gt;&#xA;&lt;p&gt;mapPartitions: do something with partition value&lt;/p&gt;&#xA;&lt;p&gt;mapPartitionsWithIndex: with index&lt;/p&gt;&#xA;&lt;p&gt;collect gives you a list&lt;/p&gt;&#xA;&lt;p&gt;union(two rdd to one rdd)&#xA;subtract&#xA;intersection&lt;/p&gt;&#xA;&lt;p&gt;glom: value -&amp;gt; list(value)&lt;/p&gt;&#xA;&lt;p&gt;foreachPartition: do thing to partition, each partition use f.&lt;/p&gt;&#xA;&lt;p&gt;fold give initial, and function, just like reduce&lt;/p&gt;&#xA;&lt;p&gt;aggregate initial seq operation, comb operation&lt;/p&gt;&#xA;&lt;p&gt;max&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
